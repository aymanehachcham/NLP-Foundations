{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7abea0ad",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All) to avoid typical problems with Jupyter notebooks. **Unfortunately, this does not work with Chrome right now, you will also need to reload the tab in Chrome afterwards**.\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\". Please put your name here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07e42b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Aymane Hachcham\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c3d3fb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a06b0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4092c0667039a312554e2a9654f525e8",
     "grade": false,
     "grade_id": "cell-000d65f4ae6fc8c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Evaluation\n",
    "\n",
    "In this (shorter) assignment, we want to compare the quality of different clustering approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "084b86b5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad68a00526ce7ac18a099b727b1d2521",
     "grade": false,
     "grade_id": "cell-d44b13e9602b47dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9ea4fee",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10e3ff83895cad9f4d12f0294405f135",
     "grade": false,
     "grade_id": "cell-5943456df56d540b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the input data\n",
    "import json, gzip\n",
    "raw = json.load(gzip.open(\"/data/simpsonswiki.json.gz\", \"rt\", encoding=\"utf-8\"))\n",
    "titles, texts, classes = [x[\"title\"] for x in raw], [x[\"text\"] for x in raw], [x[\"c\"] for x in raw]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8485ef",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6fa0809fd05f7eb0abfd47d3a574c757",
     "grade": false,
     "grade_id": "cell-358845eb04cc6a40",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This is a minimal example implementation of spherical k-means, which we will use in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "535ba240",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e1806a1463bf286e081e222d226e1d0",
     "grade": false,
     "grade_id": "cell-a2650dba6199cf26",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Vectorize the text for k-means (minimalistic)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(stop_words=\"english\", sublinear_tf=True, smooth_idf=False, min_df=5)\n",
    "vect.fit(texts)\n",
    "vect.idf_ -= 1\n",
    "tfidf, idf = vect.transform(texts), vect.idf_\n",
    "vocabulary = vect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ae62865",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "265d4bad3376697ff65fecf669834d8a",
     "grade": false,
     "grade_id": "cell-d7b358e908353de3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Minimalistic implementation for spherical k-means, so we use the same version in this assignment\n",
    "# This is NOT meant as an example of good code, but to be snort.\n",
    "def initial_centers(tfidf, k, seed):\n",
    "    return tfidf[np.random.default_rng(seed=seed).choice(tfidf.shape[0], k, replace=False)]\n",
    "\n",
    "def sphericalkmeans(tfidf, centers, max_iter=100):\n",
    "    \"\"\"REQUIRES the input to be L2 normalized, and does not handle corner cases such as empty clusters!\"\"\"\n",
    "    last_assignment = None\n",
    "    for iter in range(max_iter):\n",
    "        assignment = np.asarray((tfidf @ centers.T).argmax(axis=1)).squeeze()\n",
    "        if last_assignment is not None and all(assignment == last_assignment): break\n",
    "        last_assignment, centers = assignment, np.zeros(centers.shape)\n",
    "        for i in range(centers.shape[0]):\n",
    "            c = tfidf[assignment == i,:].sum(axis=0).A1\n",
    "            centers[i] = c / np.sqrt((c**2).sum())\n",
    "    return centers, assignment, iter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcdcd00",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c0a91db05eec6cb4b6bde40033a4c5c3",
     "grade": false,
     "grade_id": "cell-8280cd698d60e826",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implement a function to compute a cross-tabulation matrix\n",
    "\n",
    "Compute the cross-tabulation matrix compares every class to every cluster. Append an additional row and column for the cluster sizes / class totals and the dataset size. Make sure to accept clusters that are, e.g., labeled using text labels and *not* just as integers 0..k.\n",
    "\n",
    "Write your own code, do not use `pandas.crosstab`.\n",
    "\n",
    "You do not need to vectorize this, but try to use numpy operations where easily possible - in particular if you end up waiting a lot for results below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cd2cbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23a0a3bc",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8b7b2692c5b2cb0932a4f1cd9c807a7",
     "grade": false,
     "grade_id": "cell-4c6afb9d1a4a9bb0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cross_tabulation(clu, cla):\n",
    "    \"\"\"Compute the cross-tabulation matrix to compare assignments `clu` and `cla`.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    class_freq = Counter(list(zip(cla, clu))).most_common()\n",
    "    cross_tab_freq = [(x[0][0], x[0][1], x[1]) for x in class_freq]\n",
    "    sorted_freq = sorted(cross_tab_freq, key=lambda tup: tup[1])\n",
    "\n",
    "    cross_freq = []\n",
    "    for name_class in np.unique(cla):\n",
    "        columns_freq = np.zeros(len(np.unique(clu))).astype(int)\n",
    "        for x in sorted_freq:\n",
    "            if x[0] == name_class:\n",
    "                columns_freq[x[1]] = x[2]\n",
    "\n",
    "        ## Appending sum for each column\n",
    "        columns_freq = np.append(columns_freq, columns_freq.sum())\n",
    "        cross_freq.append(columns_freq)\n",
    "\n",
    "    cross_freq = np.transpose(np.array(cross_freq))\n",
    "\n",
    "    ## Appending sum for each row:\n",
    "    sums_row = [cross_freq[i,:].sum() for i in range(0, cross_freq.shape[0])]\n",
    "    cross_freq = np.column_stack((cross_freq, sums_row))\n",
    "    return cross_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5f0f2e9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "780d2e0cdf21782c006c5f50e2a98f4c",
     "grade": true,
     "grade_id": "cell-b1c59f6484e29d3a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_, _tmp, _ = sphericalkmeans(tfidf, tfidf[:5], 1)\n",
    "_tmp2 = cross_tabulation(_tmp, np.ones(tfidf.shape[0]))\n",
    "assert isinstance(_tmp2, np.ndarray), \"Must be an array\"\n",
    "assert np.issubdtype(_tmp2.dtype, np.integer), \"Must be an integer array\"\n",
    "if _tmp2.shape == (2,6): print(\"Use first parameter as first index.\")\n",
    "assert _tmp2.shape == (6,2), \"Wrong shape\"\n",
    "assert _tmp2[:-1,:-1].sum() == tfidf.shape[0], \"Not all elements\"\n",
    "assert (_tmp2[:,:-1].sum(axis=1) == _tmp2[:,-1]).all(), \"Sizes are bad\"\n",
    "assert (_tmp2[:-1].sum(axis=0) == _tmp2[-1]).all(), \"Sizes are bad\"\n",
    "assert _tmp2.sum() == 4 * tfidf.shape[0], \"Not all elements\"\n",
    "from unittest.mock import patch\n",
    "with patch('pandas.crosstab', side_effect=Exception(\"Do not use pandas.crosstab\")) as mock_p:\n",
    "    _tmp2 = cross_tabulation(_tmp, _tmp)\n",
    "assert _tmp2.shape == (6,6), \"Wrong shape\"\n",
    "assert _tmp2.sum() == 4 * tfidf.shape[0], \"Not all elements\"\n",
    "assert (_tmp2[:,:-1].sum(axis=1) == _tmp2[:,-1]).all(), \"Sizes are bad\"\n",
    "assert (_tmp2[:-1].sum(axis=0) == _tmp2[-1]).all(), \"Sizes are bad\"\n",
    "del _tmp, _tmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4890f48",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c083b96cafb44bea6d7a48fbfeba3d44",
     "grade": true,
     "grade_id": "cell-613e1eceee134b0f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_, _tmp, _ = sphericalkmeans(tfidf, tfidf[:5], 1)\n",
    "try:\n",
    "    _tmp2 = cross_tabulation(_tmp, classes)\n",
    "except Exception as e:\n",
    "    raise Exception(\"Your code probably does not accept textual class labels.\")\n",
    "assert _tmp2.shape == (6,len(np.unique(classes))+1), \"Wrong shape\"\n",
    "assert _tmp2.sum() == 4 * tfidf.shape[0], \"Not all elements\"\n",
    "assert (_tmp2[:,:-1].sum(axis=1) == _tmp2[:,-1]).all(), \"Sizes are bad\"\n",
    "assert (_tmp2[:-1].sum(axis=0) == _tmp2[-1]).all(), \"Sizes are bad\"\n",
    "del _tmp, _tmp2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ef0462",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61574652784f932e46e3e238120f4e6c",
     "grade": false,
     "grade_id": "cell-ed6cec5129fba54c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implement a function to compute the pair counts from the cross-tabulation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb3fdd2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb963639c4d8f474ff79bb976e1975a7",
     "grade": false,
     "grade_id": "cell-b2c638c196f00570",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def pair_count(crosstab):\n",
    "    \"\"\"Compute the pair count matrix from the cross-tabulation matrix.\"\"\"\n",
    "    from scipy.special import comb\n",
    "    pair_matrix = np.zeros((crosstab.shape[0], crosstab.shape[1])).astype(int)\n",
    "\n",
    "    # The pair matrix is calculated using the Binomial coefficient on the cross tabulation matrix;\n",
    "    for i in range(0, pair_matrix.shape[0]):\n",
    "        for j in range(0, pair_matrix.shape[1]):\n",
    "            pair_matrix[i][j] = comb(crosstab[i][j], 2)\n",
    "\n",
    "    return pair_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063846ac",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc588c1a5ba95ffce6aeb7cd0e0fc21d",
     "grade": true,
     "grade_id": "cell-bc3e6b835f798750",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_, _tmp, _ = sphericalkmeans(tfidf, tfidf[:5], 1)\n",
    "_tmp2 = pair_count(cross_tabulation(_tmp, np.ones(tfidf.shape[0])))\n",
    "assert isinstance(_tmp2, np.ndarray), \"Must be an array\"\n",
    "assert np.issubdtype(_tmp2.dtype, np.integer), \"Must be an integer array\"\n",
    "if _tmp2.shape == (2,6): print(\"Use first parameter as first index.\")\n",
    "assert _tmp2.shape == (6,2), \"Wrong shape\"\n",
    "assert (_tmp2[:,:-1].sum(axis=1) == _tmp2[:,-1]).all(), \"Wrong result\"\n",
    "assert not (_tmp2[:-1].sum(axis=0) == _tmp2[-1]).all(), \"Wrong result\"\n",
    "_tmp2 = cross_tabulation(_tmp, _tmp)\n",
    "assert _tmp2.shape == (6,6), \"Wrong shape\"\n",
    "assert (_tmp2[:,:-1].sum(axis=1) == _tmp2[:,-1]).all(), \"Wrong result\"\n",
    "assert (_tmp2[:-1].sum(axis=0) == _tmp2[-1]).all(), \"Wrong result\"\n",
    "del _tmp, _tmp2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cba7222",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "96d97b3ae2dda22083f4397084c8a890",
     "grade": false,
     "grade_id": "cell-762612b2921774f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Compute the Rand Index\n",
    "\n",
    "First compute the Rand Index of two assignments. You must use above functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fff8d3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e15e43600ccafae98c66eda22136b9e",
     "grade": false,
     "grade_id": "cell-7e0b2f3e32ed4a44",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def rand_index(clu, cla):\n",
    "    pair_matrix = pair_count(cross_tabulation(clu, cla))\n",
    "\n",
    "    # We have to calculate the values:\n",
    "    # Value a:\n",
    "    a = np.sum(pair_matrix[:-1,:-1])\n",
    "\n",
    "    # Value b:\n",
    "    b = np.sum(pair_matrix[:-1, -1]) - a\n",
    "\n",
    "    # Value c:\n",
    "    c = np.sum(pair_matrix[-1, :-1]) - a\n",
    "\n",
    "    # Value d:\n",
    "    d = pair_matrix[-1,-1] - a - b - c\n",
    "\n",
    "    return (a + d) / pair_matrix[-1,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f5d30a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1fa2794d73a99cf97f39f3c3d01c18d",
     "grade": true,
     "grade_id": "cell-329195060373cb5d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_, _tmp, _ = sphericalkmeans(tfidf, tfidf[:5], 1)\n",
    "from unittest.mock import patch\n",
    "with patch('__main__.cross_tabulation') as mock_u1, patch('__main__.pair_count') as mock_u2, patch('sklearn.metrics.rand_score') as mock_sk:\n",
    "    rand_index(_tmp, classes)\n",
    "assert mock_u1.called, \"Use the cross_tabulation function!\"\n",
    "assert mock_u2.called, \"Use the pair_count function!\"\n",
    "assert not mock_sk.called, \"Use your own code, not sklearn.\"\n",
    "ri = rand_index(_tmp, classes)\n",
    "assert ri <= 1, \"RI must be at most 1.\"\n",
    "assert ri > 0, \"RI must be always larger than 0.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f111c4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f5fe9ed8a961296a3ceeb59b860673e",
     "grade": true,
     "grade_id": "cell-da2e0fd36986dccb",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "import sklearn.metrics\n",
    "assert abs(ri - sklearn.metrics.rand_score(_tmp, classes)) < 1e-7, \"Result should agree with sklearn\"\n",
    "del _tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92319b59",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0df0f63cbc331ec4aad41a3d78433d76",
     "grade": false,
     "grade_id": "cell-bcc8771e63a5c1fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Compute the Adjusted Rand Index\n",
    "\n",
    "Write a function to compute the adjusted Rand index of two assignments. You must use above `pair_count` and `cross_tabulation` functions.\n",
    "\n",
    "Beware of integer overflows when using the equation from the slides. To resolve the integer overflow, transform the equation such that it has the standard form $ARI = \\frac{RI-E[RI]}{M-E[RI]}$ where RI is the rand index, $E[RI]$ is the expected value of the rand index (you need to derive this from the ARI equation given on the slides, do *not* attempt to figure out this equation directly; this assignment only needs standad high school math), and \\(M\\) is the maximum possible value of the Rand index (a constant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18672f27",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20f29162a39e21e24bff3e5247f29408",
     "grade": false,
     "grade_id": "cell-3c54c5708be33b13",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def adjusted_rand_index(clu, cla):\n",
    "    # YOUR CODE HERE\n",
    "    pair_matrix = pair_count(cross_tabulation(clu, cla))\n",
    "\n",
    "    # We have to calculate the values:\n",
    "    # Value a:\n",
    "    a = np.sum(pair_matrix[:-1,:-1])\n",
    "\n",
    "    # Value b:\n",
    "    b = np.sum(pair_matrix[:-1, -1]) - a\n",
    "\n",
    "    # Value c:\n",
    "    c = np.sum(pair_matrix[-1, :-1]) - a\n",
    "\n",
    "    # Value d:\n",
    "    d = pair_matrix[-1,-1] - a - b - c\n",
    "\n",
    "\n",
    "    ri = pair_matrix[-1][-1]*(a + d)\n",
    "    E_ri = ((a+b)*(a+c) + (c+d)*(b+d))\n",
    "    m = np.power(pair_matrix[-1][-1], 2)\n",
    "\n",
    "    return (ri - E_ri)/(m - E_ri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7101979",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef6cb334f895752bf7101fcaa1f83929",
     "grade": true,
     "grade_id": "cell-79f515ab2372b0b6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_, _tmp, _ = sphericalkmeans(tfidf, tfidf[:5], 1)\n",
    "from unittest.mock import patch\n",
    "with patch('__main__.cross_tabulation') as mock_u1, patch('__main__.pair_count') as mock_u2, patch('sklearn.metrics.adjusted_rand_score') as mock_sk, patch('sklearn.metrics.rand_score') as mock_sk2:\n",
    "    adjusted_rand_index(_tmp, classes)\n",
    "assert mock_u1.called, \"Use the cross_tabulation function!\"\n",
    "assert mock_u2.called, \"Use the pair_count function!\"\n",
    "assert not mock_sk.called, \"Use your own code, not sklearn.\"\n",
    "assert not mock_sk2.called, \"Use your own code, not sklearn.\"\n",
    "ari = adjusted_rand_index(_tmp, classes)\n",
    "assert ari <= 1, \"ARI must be at most 1\"\n",
    "assert ari > 0, \"This clustering must score better than random.\"\n",
    "del _tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bc4b82",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d986b76415be200de5452c5f322e4ff4",
     "grade": true,
     "grade_id": "cell-1113a5c4487f666f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_, _tmp, _ = sphericalkmeans(tfidf, tfidf[:5], 1)\n",
    "ari = adjusted_rand_index(_tmp, classes)\n",
    "import sklearn.metrics\n",
    "assert abs(ari - sklearn.metrics.adjusted_rand_score(_tmp, classes)) < 1e-7, \"Result should agree with sklearn\"\n",
    "del _tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb782b2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "49b825fac051ea351dc18b699e95dd15",
     "grade": false,
     "grade_id": "cell-0ef157590183b75b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Compute the Normalized Mutual Information\n",
    "\n",
    "Write a function to compute the Normalized Mutual Information (with arithmetic averaging) of two assignments.\n",
    "You must use above `pair_count` and `cross_tabulation` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90e3818",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05543937f6c1edf33e4463e24a216453",
     "grade": false,
     "grade_id": "cell-5b724c2aa3e72f00",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def normalized_mutual_information(clu, cla):\n",
    "    # YOUR CODE HERE\n",
    "    # We use the pair matrix:\n",
    "    pair_matrix =  cross_tabulation(clu, cla)\n",
    "\n",
    "    import math\n",
    "\n",
    "\n",
    "    nmi_matrix_ck = np.zeros((pair_matrix.shape[0]-1, pair_matrix.shape[1]-1))\n",
    "\n",
    "    n = pair_matrix[-1, -1]\n",
    "    ci = pair_matrix[:-1,-1]\n",
    "    kj = pair_matrix[-1,:-1]\n",
    "\n",
    "    # i_cc = -sum(list(map(lambda t: t/pair_matrix[-1,-1] * np.log(t/pair_matrix[-1,-1]), pair_matrix[:-1,-1])))\n",
    "    i_cc = -sum([el/n * math.log(el/n) for el in ci])\n",
    "    i_kk = -sum([el/n * math.log(el/n) for el in kj])\n",
    "    # i_kk = -sum(list(map(lambda t: t/pair_matrix[-1,-1] * np.log(t/pair_matrix[-1,-1]), pair_matrix[-1,:-1])))\n",
    "\n",
    "    for i in range(0, pair_matrix.shape[0]-1):\n",
    "        for j in range(0, pair_matrix.shape[1]-1):\n",
    "            nmi_matrix_ck[i][j] = pair_matrix[i][j]/n * math.log2( n*(pair_matrix[i][j]) / ( ci[i] * kj[j] ))\n",
    "\n",
    "    ck = np.sum(nmi_matrix_ck)\n",
    "\n",
    "    nmi = (ck * 2) / (i_cc + i_kk)\n",
    "    return nmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d111eb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "13daec252ab272e117490e5fa4dc915a",
     "grade": true,
     "grade_id": "cell-919137944c4c0c89",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_, _tmp, _ = sphericalkmeans(tfidf, tfidf[:5], 1)\n",
    "from unittest.mock import patch\n",
    "with patch('sklearn.metrics.normalized_mutual_info_score', side_effect=Exception(\"Use your own code, not skelarn\")) as mock_sk1,  patch('sklearn.metrics.mutual_info_score', side_effect=Exception(\"Use your own code, not skelarn\")) as mock_sk2:\n",
    "    normalized_mutual_information(_tmp, classes)\n",
    "nmi = normalized_mutual_information(_tmp, classes)\n",
    "assert nmi <= 1, \"NMI must be at most 1\"\n",
    "assert nmi > 0, \"This clustering must score better than random.\"\n",
    "del _tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0c5169",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d6e20382134c8e8995838384b312ed8",
     "grade": true,
     "grade_id": "cell-8987caee47e63f78",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_, _tmp, _ = sphericalkmeans(tfidf, tfidf[:5], 1)\n",
    "nmi = normalized_mutual_information(_tmp, classes)\n",
    "import sklearn.metrics\n",
    "assert abs(nmi - sklearn.metrics.normalized_mutual_info_score(_tmp, classes)) < 1e-10, \"Result should agree with sklearn\"\n",
    "del _tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0da594",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "003ec7db49b44ca56647ef6dc67ea557",
     "grade": false,
     "grade_id": "cell-528f9f2cca4e7e38",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Finding the best clustering\n",
    "\n",
    "for $k=1..15$, and a fixed random seed of 0, find the best spherical k-means clustering by NMI compared to the classes stored in `classes` above (note that this will not generally be possible, as our data usually will not be labeled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5153913",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a113c685be46afb769d2e462c856bc3",
     "grade": false,
     "grade_id": "cell-c608e9355ae7e4b8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "bestk = None # Store best k here\n",
    "bestnmi = None # Store the best NMI here\n",
    "bestassignment = None # Store the best assignment here\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "print(\"The best k is\", bestk, \"scoring\", bestnmi)\n",
    "# Hint: it will *not* score very good. The classes are not clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877f436a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bfcd004607f35e14c0aac8c07633d0af",
     "grade": true,
     "grade_id": "cell-75f2a8a9685b1144",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "assert bestk > 0 and bestk <= 15\n",
    "assert bestk == len(np.unique(bestassignment)), \"Inconsistent result\"\n",
    "assert abs(bestnmi-sklearn.metrics.normalized_mutual_info_score(bestassignment, classes)) < 1e-7, \"Inconsistent result\"\n",
    "assert all(bestassignment == sphericalkmeans(tfidf, initial_centers(tfidf, bestk, 0))[1]), \"Inconsistent result\"\n",
    "assert bestk > 2, \"There should be something better\"\n",
    "assert bestk < 15, \"There should be something better\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554575ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e80cdb14b5240d961a2ce03691672d2e",
     "grade": true,
     "grade_id": "cell-e93e6fa091666397",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Additional Automatic tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09502e4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5430abf1c9b3a3483a4da4c29064687e",
     "grade": false,
     "grade_id": "cell-bfe6416f6601f045",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Explore the result\n",
    "\n",
    "Explore the clustering result, by comparing it to the original classes.\n",
    "\n",
    "For each cluster, return the cluster label, the three top classes, and the percentages of the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3836bfa5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5449ee738333b99dddd5453d1cd707d5",
     "grade": false,
     "grade_id": "cell-63587c44768ee69f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def top_classes(clu, cla):\n",
    "    \"\"\"For each cluster, give the top three classes and their share of the data each.\"\"\"\n",
    "    # For each cluster, call yield label, *top3, *shares to return a 7-tuple.\n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2390fec",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d3f61b95b0e9a5da01b5596edfe9629",
     "grade": true,
     "grade_id": "cell-2536f746075d1e01",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_tmp = top_classes(classes, classes)\n",
    "import types\n",
    "assert isinstance(_tmp, types.GeneratorType), \"You did not use `yield`.\"\n",
    "_tmp = list(_tmp)\n",
    "assert len(_tmp) == len(np.unique(classes)), \"Wrong number of results\"\n",
    "for row in _tmp:\n",
    "    assert len(row) == 7, \"Not a 7-tuple\"\n",
    "    assert row[0] in classes, \"Not a label\"\n",
    "    assert row[0] == row[1], \"Incorrect result\"\n",
    "    assert row[4:] == (1.,0.,0.), \"Incorrect result\"\n",
    "del _tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1c6e71",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fd5e5fe14192e67f67d0611413ea90a",
     "grade": true,
     "grade_id": "cell-31342b8247fac176",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_tmp = top_classes(bestassignment, classes)\n",
    "import types\n",
    "assert isinstance(_tmp, types.GeneratorType), \"You did not use `yield`.\"\n",
    "_tmp = list(_tmp)\n",
    "assert len(_tmp) == bestk, \"Wrong number of results\"\n",
    "for row in _tmp:\n",
    "    assert len(row) == 7, \"Not a 7-tuple\"\n",
    "    assert row[1] in classes, \"Not a label\"\n",
    "# Additional hidden tests\n",
    "del _tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4129522",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1e24764e369997816b5c2c5e39a049b",
     "grade": false,
     "grade_id": "cell-2773fe306b0aa792",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Explore your best clustering!\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

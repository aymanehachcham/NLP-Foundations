{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c54cb084",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All) to avoid typical problems with Jupyter notebooks. **Unfortunately, this does not work with Chrome right now, you will also need to reload the tab in Chrome afterwards**.\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\". Please put your name here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5a21cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Aymane Hachcham\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01071fe7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1e8836",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f5be5dd3c2670d143a21f7e718367c27",
     "grade": false,
     "grade_id": "cell-8ade67d02be836f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Spherical k-Means Clustering\n",
    "\n",
    "In this assignment, your task is to implement spherical k-means clustering *yourself*.\n",
    "\n",
    "You will need to pay attention to performance. Using \"for\" loops over all instances and variables will not work, but instead you need to perform efficient vectorized operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "32bea512",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67299be7a0f56c95e684f3a80dea61f9",
     "grade": false,
     "grade_id": "cell-6ee0b11ce02911bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "61f459d8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c087d041cbbee152cfea91ed54d7e1eb",
     "grade": false,
     "grade_id": "cell-a318b7ba2ab576a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the input data\n",
    "import json, gzip\n",
    "raw = json.load(gzip.open(\"/data/simpsonswiki.json.gz\", \"rt\", encoding=\"utf-8\"))\n",
    "titles, texts, classes = [x[\"title\"] for x in raw], [x[\"text\"] for x in raw], [x[\"c\"] for x in raw]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae9fe36",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d97aa44808053ad1b6c0c2c0102e03b7",
     "grade": false,
     "grade_id": "cell-d4ae20c12c5d69b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Before you begin anything, always first have a look at the data you are dealing with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "585b5209",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8294c9fa802ba3042349c5a6a6aabcb",
     "grade": false,
     "grade_id": "cell-b8e2ea1eb96f0822",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Locations',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Guest stars',\n",
       " 'Characters',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Trivia',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Guest stars',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Objects',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Locations',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Objects',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Trivia',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Locations',\n",
       " 'Episodes',\n",
       " 'Locations',\n",
       " 'Locations',\n",
       " 'Locations',\n",
       " 'Locations',\n",
       " 'Locations',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Guest stars',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Guest stars',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Objects',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Objects',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Locations',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Locations',\n",
       " 'Episodes',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Guest stars',\n",
       " 'Episodes',\n",
       " 'Locations',\n",
       " 'Episodes',\n",
       " 'Objects',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Songs',\n",
       " 'Songs',\n",
       " 'Songs',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Songs',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Locations',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Objects',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Objects',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Guest stars',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Guest stars',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Trivia',\n",
       " 'Guest stars',\n",
       " 'Objects',\n",
       " 'Songs',\n",
       " 'Songs',\n",
       " 'Songs',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Locations',\n",
       " 'Songs',\n",
       " 'Objects',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Objects',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Objects',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Locations',\n",
       " 'Locations',\n",
       " 'Locations',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Locations',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Locations',\n",
       " 'Locations',\n",
       " 'Locations',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Objects',\n",
       " 'Objects',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Objects',\n",
       " 'Characters',\n",
       " 'Guest stars',\n",
       " 'Locations',\n",
       " 'Episodes',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Characters',\n",
       " 'Objects',\n",
       " 'Locations',\n",
       " 'Guest stars',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Guest stars',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Locations',\n",
       " 'Episodes',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Objects',\n",
       " 'Guest stars',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Guest stars',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Objects',\n",
       " 'Locations',\n",
       " 'Objects',\n",
       " 'Locations',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Locations',\n",
       " 'Locations',\n",
       " 'Objects',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Locations',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Guest stars',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Objects',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Songs',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Locations',\n",
       " 'Objects',\n",
       " 'Trivia',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Objects',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Objects',\n",
       " 'Objects',\n",
       " 'Characters',\n",
       " 'Guest stars',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Songs',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Objects',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Episodes',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Objects',\n",
       " 'Characters',\n",
       " 'Guest stars',\n",
       " 'Songs',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Objects',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Guest stars',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Guest stars',\n",
       " 'Objects',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Guest stars',\n",
       " 'Characters',\n",
       " 'Locations',\n",
       " 'Couch Gags',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Guest stars',\n",
       " 'Characters',\n",
       " 'Objects',\n",
       " 'Characters',\n",
       " 'Trivia',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Locations',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Characters',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Characters',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Guest stars',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Trivia',\n",
       " 'Trivia',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Objects',\n",
       " 'Locations',\n",
       " 'Locations',\n",
       " 'Locations',\n",
       " 'Locations',\n",
       " 'Locations',\n",
       " 'Locations',\n",
       " 'Locations',\n",
       " 'Locations',\n",
       " 'Locations',\n",
       " 'Locations',\n",
       " 'Locations',\n",
       " 'Objects',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " 'Locations',\n",
       " 'Characters',\n",
       " 'Objects',\n",
       " 'Characters',\n",
       " 'Characters',\n",
       " ...]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a411c2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f29cf7d2629a4b9e28767715626894b4",
     "grade": false,
     "grade_id": "cell-e7eb2da44a681f31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Vectorize the text\n",
    "\n",
    "Vectorize the Wiki texts, use the standard TF-IDF from the lecture (standard SMART `ltc` version, lowercase, *not* the scikit-learn variant) as discussed in the previous assignments. Use a minimum document frequency of 5 and standard english stopwords to reduce the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d1387a73",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a47b94c3e41935b62ccc5b17d9259727",
     "grade": false,
     "grade_id": "cell-cab90d6625b6f73e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer # Please use this\n",
    "from scipy.sparse import spdiags\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=5, stop_words='english')\n",
    "dtm = vectorizer.fit_transform(texts)\n",
    "\n",
    "tfidf = None # sparse tf-idf matrix\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "idf = None # IDF values\n",
    "\n",
    "def tf(dtm):\n",
    "    tf_matrix = dtm.astype(np.float32)\n",
    "    tf_matrix.data = 1 + np.log(tf_matrix.data)\n",
    "    \n",
    "    return tf_matrix\n",
    "\n",
    "def idf(dtm):\n",
    "    idf_matrix = np.log(dtm.shape[0] / (dtm.getnnz(0)))\n",
    "    return idf_matrix\n",
    "\n",
    "# _tf, _idf = tf(dtm), idf(dtm)\n",
    "# mat = spdiags(_idf, np.array([0]), _idf.shape[0], _idf.shape[0], format=None)\n",
    "\n",
    "def tfidf(dtm):\n",
    "    _tf, _idf = tf(dtm), idf(dtm)\n",
    "    \n",
    "    sparse_matrix = _tf @ scipy.sparse.spdiags(_idf, 0, _idf.shape[0], _idf.shape[0])\n",
    "    _tfidf = 1/np.sqrt(sparse_matrix.power(2).sum(axis=1).A1)\n",
    "    return scipy.sparse.spdiags(_tfidf, 0, _tfidf.shape[0], _tfidf.shape[0]) @ sparse_matrix\n",
    "\n",
    "tfidf = tfidf(dtm)\n",
    "idf = idf(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a61e02da",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "626eb7035e0dec5acc9360463e653167",
     "grade": false,
     "grade_id": "cell-15ca0b88941a88a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zorina</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zsa</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zuylen</th>\n",
       "      <th>zzyzwicz</th>\n",
       "      <th>zörker</th>\n",
       "      <th>üter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10121</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10122</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10123</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10124</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10125</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10126 rows × 14153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        00  000   01   02   04   05   06   07   08        10  ...  zoo  zooms  \\\n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0    0.0   \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0    0.0   \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.087577  ...  0.0    0.0   \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0    0.0   \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0    0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...       ...  ...  ...    ...   \n",
       "10121  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0    0.0   \n",
       "10122  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0    0.0   \n",
       "10123  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0    0.0   \n",
       "10124  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0    0.0   \n",
       "10125  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0    0.0   \n",
       "\n",
       "       zorina  zorro  zsa  zuckerberg  zuylen  zzyzwicz  zörker  üter  \n",
       "0         0.0    0.0  0.0         0.0     0.0       0.0     0.0   0.0  \n",
       "1         0.0    0.0  0.0         0.0     0.0       0.0     0.0   0.0  \n",
       "2         0.0    0.0  0.0         0.0     0.0       0.0     0.0   0.0  \n",
       "3         0.0    0.0  0.0         0.0     0.0       0.0     0.0   0.0  \n",
       "4         0.0    0.0  0.0         0.0     0.0       0.0     0.0   0.0  \n",
       "...       ...    ...  ...         ...     ...       ...     ...   ...  \n",
       "10121     0.0    0.0  0.0         0.0     0.0       0.0     0.0   0.0  \n",
       "10122     0.0    0.0  0.0         0.0     0.0       0.0     0.0   0.0  \n",
       "10123     0.0    0.0  0.0         0.0     0.0       0.0     0.0   0.0  \n",
       "10124     0.0    0.0  0.0         0.0     0.0       0.0     0.0   0.0  \n",
       "10125     0.0    0.0  0.0         0.0     0.0       0.0     0.0   0.0  \n",
       "\n",
       "[10126 rows x 14153 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.sparse.from_spmatrix(tfidf, columns=vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cc9d4b28",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "370d665eef638f73ee0cd4a079db277e",
     "grade": true,
     "grade_id": "cell-b86cbb28a960c488",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "assert tfidf is not None and vocabulary is not None, \"Variables not set\"\n",
    "assert tfidf.shape[0] == len(texts), \"Missing documents\"\n",
    "assert len(vocabulary) == tfidf.shape[1], \"Vocabulary size does not match\"\n",
    "assert isinstance(tfidf, scipy.sparse.csr_matrix), \"Not a sparse matrix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5e425962",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b5a55f08654bc681b8c357e953e5f04",
     "grade": true,
     "grade_id": "cell-9de75579d3f50f9c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "assert len(idf) == tfidf.shape[1], \"IDF size does not match\"\n",
    "assert idf.max() != 1 +np.log(len(texts)/5), \"No, default sklearn is NOT okay\"\n",
    "assert idf.max() == np.log(len(texts)/5), \"IDF does not match definition\"\n",
    "assert not isinstance(idf, scipy.sparse.csr_matrix), \"IDF should not be sparse!\"\n",
    "assert isinstance(idf, np.ndarray), \"IDF must be an array\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b90bdb4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "00f4d1f2e07fe819f7473779b12fdaf3",
     "grade": false,
     "grade_id": "cell-b3f524f7150a1704",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Reassignment step\n",
    "\n",
    "Implement the reassignment step of **spherical** k-means. Use **vectorized code**, or it will likely be too slow.\n",
    "\n",
    "Do *not* use a Python `for` loop, and do *not* convert the input data to a dense matrix (slow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4333a9df",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d65d34e37470e0645b94c7c681c412ec",
     "grade": false,
     "grade_id": "cell-9dc7f534cb8bf484",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 4 1 1 4 1 4 1 0 2 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "def reassign(tfidf, centers):\n",
    "    \"\"\"Reassign each object in tfidf to the most similar center.\n",
    "       Return a flat array, not a matrix.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    similar_centers = np.array((centers @ tfidf.T).argmax(axis=0)).flatten()\n",
    "    return similar_centers\n",
    "# Test run\n",
    "print(reassign(tfidf[:20], tfidf[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "80ab7e58",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "306b0a88705f9f8463a77aae03d64b8b",
     "grade": true,
     "grade_id": "cell-2d129ba30ec221a5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_test = reassign(tfidf, tfidf[:5])\n",
    "assert _test.shape == (tfidf.shape[0],), \"Return shape does not match\"\n",
    "assert (_test[:5] == np.arange(0,5)).all(), \"Incorrect results\"\n",
    "assert _test.min() == 0 and _test.max() == 4, \"Invalid values in array\"\n",
    "assert isinstance(_test, np.ndarray), \"Return value is not a dense array -- you may need to use asarray() on the return value, unfortunately.\"\n",
    "assert _test.dtype == np.int64, \"Not an integer array\"\n",
    "del _test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5012d02a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b480489ea49d18b25bb39f4aae2b7786",
     "grade": true,
     "grade_id": "cell-a82667b395eb4690",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "from unittest.mock import patch\n",
    "with patch('__main__.range') as mock_r1, patch('numpy.arange') as mock_r2:\n",
    "    reassign(tfidf[:10], tfidf[:5])\n",
    "assert not mock_r1.called and not mock_r2.called, \"Vectorize your code! Otherwise you will be waiting a long time below.\"\n",
    "with patch('sklearn.metrics.pairwise.cosine_similarity') as mock_c1, patch('sklearn.metrics.pairwise.cosine_distances') as mock_c2:\n",
    "    reassign(tfidf[:10], tfidf[:5])\n",
    "assert not mock_c1.called and not mock_c2.called, \"Use your own code, not sklearn.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f785653",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5803c4d4f1c388d2004d57eb4a47ef04",
     "grade": false,
     "grade_id": "cell-29f37d500eea3a8f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Recompute the cluster centers\n",
    "\n",
    "Given a cluster assignment, recompute the cluster centers as used by *spherical* k-means.\n",
    "\n",
    "Vectorize your code: do not iterate over all points with a Python for loop\n",
    "\n",
    "Hint: for the assignment, it is okay to assume that a cluster never becomes empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "22f990f4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "52f54939125638ca9a3e94f012771e81",
     "grade": false,
     "grade_id": "cell-e88d9b8f12c5e030",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def new_centers(tfidf, assignment):\n",
    "    \"\"\"Return a matrix containing the new cluster centers for spherical k-means.\"\"\"\n",
    "    centers = [] # Okay to use a list or an array for the assignment\n",
    "    # YOUR CODE HERE\n",
    "    for text_cluster in np.unique(assignment):\n",
    "        k_centers = tfidf[assignment == text_cluster].sum(axis=0).A1\n",
    "        centers.append(k_centers/np.sqrt(np.square(k_centers).sum()))\n",
    "        \n",
    "    return np.array(centers) # Always return an array, copying is okay for the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "23992775",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38a3ad0cabd3d7f3aef407877f2fe21d",
     "grade": true,
     "grade_id": "cell-55306421570c0407",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_tmp = new_centers(tfidf[:10], np.linspace(0, 4, 10).astype(np.int64))\n",
    "assert len(_tmp) == 5, \"Wrong number of centers.\"\n",
    "for r in _tmp: assert r.shape[-1] == tfidf.shape[-1], \"Not a proper center\"\n",
    "del _tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "66ab5429",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95b2eeec454a53918d72da78b3b6d226",
     "grade": true,
     "grade_id": "cell-635f787b1b72d489",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_tmp = new_centers(tfidf, np.zeros((tfidf.shape[0],)))\n",
    "assert abs(np.array(_tmp).mean()-tfidf.mean()) > 1e-5, \"This is not spherical k-means.\"\n",
    "del _tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8621426f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "681de45839d96ff6d72eba68cf798fd0",
     "grade": false,
     "grade_id": "cell-9f9375c7ac7788b9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Initialization\n",
    "\n",
    "Now write initialization code. Given a random generator *seed*, chose `k` objects as initial cluster centers without replacement. Please use numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e9641a06",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b37307ca18e9d06dc825a07cbc192154",
     "grade": false,
     "grade_id": "cell-11997ba43dbe994a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "\n",
    "def initial_centers(tfidf, k, seed):\n",
    "    \"\"\"Choose k initial cluster centers.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    initial_dict = {}\n",
    "    ind = np.random.randint(0, tfidf.shape[0], k)\n",
    "    \n",
    "    for index in range(0, len(ind)):\n",
    "        initial_dict[index] = ind[index]\n",
    "    \n",
    "    centers = tfidf[list(map(initial_dict.get, list(set(safe_sparse_dot(tfidf, tfidf[np.random.randint(0, tfidf.shape[0], k)].T, dense_output=True).argmax(axis=1)))))].toarray()\n",
    "    \n",
    "    return np.array(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "310e146e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b04c316e37a39d8a7618bc51b341a4b",
     "grade": true,
     "grade_id": "cell-40ca850292aeacc5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_tmp = initial_centers(tfidf, 10, 42)\n",
    "assert isinstance(_tmp, scipy.sparse.csr_matrix) or len(_tmp) == 10, \"Wrong number of centers.\"\n",
    "assert not isinstance(_tmp, scipy.sparse.csr_matrix) or _tmp.shape[0] == 10, \"Wrong number of centers.\"\n",
    "for r in _tmp: assert r.shape[-1] == tfidf.shape[-1], \"Not a proper center.\"\n",
    "del _tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ba2b2f83",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab289ab0b0d7bcd52fdf7ad92a3ffe43",
     "grade": true,
     "grade_id": "cell-279a7fbe8935c422",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "assert (initial_centers(tfidf, 1, 42)-initial_centers(tfidf, 1, 42)).sum() == 0, \"Seeding not okay.\"\n",
    "assert (initial_centers(tfidf, 1, 42)-initial_centers(tfidf, 1, 21)).sum() != 0, \"Seeding not okay.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aa08dc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cf2dfcbd51252039116c1f5065cdf8eb",
     "grade": false,
     "grade_id": "cell-41f90dfcd5e009de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implement a Quality Measure\n",
    "\n",
    "As quality measure, compute the *sum* of cosine similarities of every point to its cluster center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "551561f7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "feaba4515dcbb0057f8b121717b57144",
     "grade": false,
     "grade_id": "cell-0f1fd8bd1523d029",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def quality(tfidf, centers, assignment):\n",
    "    \"\"\"Evaluate the quality given the current centers and cluster assignment.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    s = 0\n",
    "    for index in set(assignment):\n",
    "        s = s + (tfidf[assignment== index] @ centers[index].T).sum()\n",
    "        \n",
    "    #raise NotImplementedError()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dcebf239",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da944c441f1519977bb36a4af3e3172a",
     "grade": true,
     "grade_id": "cell-bad393bd8d4ac0eb",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "# This test is likely slow if you use a \"for\" loop in quality(). But that is okay.\n",
    "_tmp = quality(tfidf, tfidf[0], np.zeros((tfidf.shape[0],)))\n",
    "assert quality(tfidf, tfidf, np.arange(0,tfidf.shape[0])) == tfidf.shape[0], \"Result incorrect\"\n",
    "assert _tmp > 100, \"This largely random result should score better\"\n",
    "assert _tmp < 500, \"This largely random result should score less\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02893b9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe73723d69e51c90d53ab3f13a0f2310",
     "grade": false,
     "grade_id": "cell-2189633f87040d97",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As a reference value, compute the quality of assigning every object to the global *spherical* center.\n",
    "\n",
    "Hint: you can use `new_centers` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4bfac260",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4e203147f070ec431918097e957e214",
     "grade": false,
     "grade_id": "cell-3bd3e06fadf9fb42",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity sum to center: 1042.5999538592491\n",
      "Average similarity to center: 0.10296266579688418\n"
     ]
    }
   ],
   "source": [
    "center1 = None # Compute the overall center\n",
    "sim1 = 0 # Compute the overall similarity\n",
    "\n",
    "# YOUR CODE HERE\n",
    "center1 = new_centers(tfidf, np.zeros((tfidf.shape[0],), dtype=np.int64))\n",
    "sim1 = quality(tfidf, center1, np.zeros((tfidf.shape[0],), dtype=np.int64))\n",
    "\n",
    "print(\"Similarity sum to center:\", sim1)\n",
    "print(\"Average similarity to center:\", sim1 / tfidf.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6dfab550",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "601bfe36346b9b08b522e7c72e2fecab",
     "grade": true,
     "grade_id": "cell-1c343b3f7709108b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "assert center1 is not None, \"Not answered.\"\n",
    "assert abs(np.array(center1).mean()-tfidf.mean()) > 1e-5, \"This is not the spherical center.\"\n",
    "assert sim1 > 500, \"This result should score better\"\n",
    "assert sim1 < 2000, \"This result should score less\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03cfe9c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "690217ba22abcb6d90665c47aaa7fb14",
     "grade": false,
     "grade_id": "cell-8f41632af68aa85f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implement Spherical k-Means\n",
    "\n",
    "Now use these methods to implement spherical k-means clustering. Stop after a maximum number of iterations, or if no point is reassigned.\n",
    "\n",
    "Return the cluster centers, the final cluster assignment, and an array of quality scores evaluated every time *after* reassigning the points to the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a5b16232",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "90059fd4e04e472c591848f5cd250858",
     "grade": false,
     "grade_id": "cell-36736752f7e3e89c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def spherical_kmeans(tfidf, initial_centers, max_iter=100):\n",
    "    qualities = []\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    centers = initial_centers\n",
    "    assignment = None\n",
    "    for index in range(0, max_iter):\n",
    "        assign_again = reassign(tfidf, centers)\n",
    "        \n",
    "        qualities.append(quality(tfidf, centers, assign_again))\n",
    "        if assignment is not None and all(assignment == assign_again):\n",
    "            break\n",
    "        \n",
    "        assignment = assign_again\n",
    "        centers = new_centers(tfidf, assignment)\n",
    "    \n",
    "    return centers, assignment, qualities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3353e1a0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "90e70cbbc5389e8eaf3b8ae389445d86",
     "grade": true,
     "grade_id": "cell-1d5aea05fd897805",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "from unittest.mock import patch\n",
    "with patch('__main__.reassign') as mock_1, patch('__main__.new_centers') as mock_2, patch('__main__.quality') as mock_3:\n",
    "    spherical_kmeans(tfidf, tfidf[0], 1)\n",
    "    assert mock_1.called, \"You did not use reassign\"\n",
    "    assert mock_2.called, \"You did not use new_centers\"\n",
    "    assert mock_3.called, \"You did not use quality\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5716b6d2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bfbfb82f8168394b997f9ac26068c8bd",
     "grade": false,
     "grade_id": "cell-7b71c6241a95379f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## CLUSTER!\n",
    "\n",
    "Now try out if your code works! First, cluster with `k=2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3304ca20",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4fe6305f8022e3c5519fcdf9194635e",
     "grade": false,
     "grade_id": "cell-368323bd1298f19f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[167.6762003518968,\n",
       " 1116.224472635951,\n",
       " 1159.7350903225708,\n",
       " 1172.9851729628508,\n",
       " 1178.0056844418848,\n",
       " 1180.1271594505547,\n",
       " 1180.9847121420466,\n",
       " 1181.2532651430688,\n",
       " 1181.4404554346825,\n",
       " 1181.5492072542543,\n",
       " 1181.5983030670272,\n",
       " 1181.624383568244,\n",
       " 1181.635029531228,\n",
       " 1181.6503654295382,\n",
       " 1181.6697869663308,\n",
       " 1181.7230700869272,\n",
       " 1181.7481779426025,\n",
       " 1181.752141412929]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "centers = initial_centers(tfidf, 2, 21)\n",
    "centers, assign, qualities = spherical_kmeans(tfidf, centers, 100)\n",
    "qualities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "edf11569",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4416f3f62d39dd2f77af31d4f445ae9b",
     "grade": true,
     "grade_id": "cell-f65527fa617330d4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_tmp = spherical_kmeans(tfidf, tfidf[[0,1]], 100)\n",
    "assert len(_tmp[0]) == 2, \"Wrong number of clusters\"\n",
    "assert _tmp[0].shape[-1] == tfidf.shape[-1], \"Centers have bad shape\"\n",
    "assert sorted(np.unique(_tmp[1])) == [0,1], \"Missing some clusters?\"\n",
    "assert len(_tmp[2]) < 90, \"Should take much fewer iterations\"\n",
    "assert _tmp[2] == sorted(_tmp[2]), \"Quality must be increasing\"\n",
    "assert _tmp[2][-1] == quality(tfidf, _tmp[0], _tmp[1]), \"Quality wrong\"\n",
    "assert len(spherical_kmeans(tfidf, tfidf[[0,1]], 2)[2]) == 2, \"max_iter incorrect.\"\n",
    "del _tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b91a5980",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ba041bbfa2d0e000a5f439b35704a9f",
     "grade": true,
     "grade_id": "cell-4e50ee8ca3eeaddd",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_tmp = spherical_kmeans(tfidf, tfidf[[0,1]], 5)\n",
    "_tmp2 = spherical_kmeans(tfidf, tfidf[[0,1]], 10)\n",
    "assert _tmp[2] == _tmp2[2][:5]\n",
    "del _tmp, _tmp2\n",
    "# Additional hidden tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab753b27",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f089f8b41aaee80e75bfa1c3ce1f3d57",
     "grade": false,
     "grade_id": "cell-326de1886bcc2d65",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Study the Clusters\n",
    "\n",
    "As we cannot rely on heuristics such as the \"knee\" to choose the number of clusters, we need to perform manual inspection:\n",
    "\n",
    "- what are the most important words of each cluster?\n",
    "- what are the most central documents in each cluster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f45418a7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c6ffbe165d6d57ebc3242fca5f926ff",
     "grade": false,
     "grade_id": "cell-4204f6945c5ba9a1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def most_important(vocabulary, center, k=10):\n",
    "    \"\"\"Find the most important words for each cluster.\"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    important_words = [vocabulary[word] for word in center.argsort() [-1::-1][:k]]\n",
    "    return important_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6efca1af",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f813f392e7df05d73f0f3b6d4d2d4fa",
     "grade": true,
     "grade_id": "cell-0ddfa91ab7050d6e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_tmp = tfidf[0].toarray()[0]\n",
    "assert len(most_important(vocabulary, _tmp, 42)) == 42, \"Wrong number of results.\"\n",
    "for x in most_important(vocabulary, _tmp): assert isinstance(x, str), \"Not words.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ca2419cf",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "86026da63de2b2622711e72d3d95efe6",
     "grade": false,
     "grade_id": "cell-e0a391ee2190aa32",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def most_central(tfidf, centers, assignment, i, k=5):\n",
    "    \"\"\"Find the most central documents of cluster i\"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    final_central_result = (tfidf@centers[i].T).flatten()*(assignment==i)\n",
    "    return final_central_result.argsort() [-1::-1][:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c7308358",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b66d9afb3e977829d4b83b3b0220da0",
     "grade": true,
     "grade_id": "cell-451b762239119d0c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "assert len(most_central(tfidf, tfidf[[0]].toarray(), np.zeros((tfidf.shape[0],)), 0, 42)) == 42, \"Wrong number of results.\"\n",
    "assert (most_central(tfidf, tfidf[[0,1]].toarray(), np.arange(0,tfidf.shape[0])&1, 0, 10)&1==0).all(), \"Only documents from the same cluster may be returned.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf4985c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d56fbaa21658e054bddfa06e7e47439",
     "grade": false,
     "grade_id": "cell-737de4988a708aa4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Explain your Clusters\n",
    "\n",
    "Write a function to print a cluster explanation using above functions, and run it for k=20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "592a4a56",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40ae1be9cbca5b9434089f5720d7bf72",
     "grade": false,
     "grade_id": "cell-0f15b90ed9ce4d0e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def explain(tfidf, vocabulary, titles, centers, assignment):\n",
    "    \"\"\"Use what you built.\"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    for index, cluster in enumerate(centers):\n",
    "        print(f\"The Cluster number {index + 1} and the number of words {len(cluster[cluster != 0])}\")\n",
    "        print(\"----------------------#####----------------------\")\n",
    "        print(\"The Top Important Words: \", \"; \".join(most_important(vocabulary, cluster)))\n",
    "        print(\"The Top title entities : \\n\")\n",
    "        for x in most_central(tfidf, centers, assignment, index):\n",
    "            print(\"\", titles[x])\n",
    "        print(\"----------------------#####----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3f5a2659",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "64db950b735a7d946fd107445db64a68",
     "grade": false,
     "grade_id": "cell-ad57fb49f30eae7d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cluster number 1 and the number of words 4610\n",
      "----------------------#####----------------------\n",
      "The Top Important Words:  krusty; clown; burger; bart; brand; history; springfield; rabbi; krustofsky; kancelled\n",
      "The Top title entities : \n",
      "\n",
      " Bill (Accountant)\n",
      " Little Bearded Woman\n",
      " Krusty's ex-girlfriend\n",
      " The Krusty the Clown Show\n",
      " It's the Most Wonderful Time of the Year\n",
      "----------------------#####----------------------\n",
      "The Cluster number 2 and the number of words 13823\n",
      "----------------------#####----------------------\n",
      "The Top Important Words:  homer; bart; marge; lisa; episode; simpsons; moe; family; tells; springfield\n",
      "The Top title entities : \n",
      "\n",
      " Homer Simpson\n",
      " Bart Simpson\n",
      " Homer Strangles Bart (or Someone)\n",
      " Robert Terwilliger\n",
      " Opening Sequence\n",
      "----------------------#####----------------------\n",
      "The Cluster number 3 and the number of words 4100\n",
      "----------------------#####----------------------\n",
      "The Top Important Words:  book; comic; books; guy; history; read; lisa; reading; angelica; series\n",
      "The Top title entities : \n",
      "\n",
      " Comic Book Guy's wife (The Joy of Sect)\n",
      " Equations\n",
      " Stats\n",
      " Bat-Shriek\n",
      " I Am Smart, Much Smarter than You, Hibbert\n",
      "----------------------#####----------------------\n",
      "The Cluster number 4 and the number of words 5250\n",
      "----------------------#####----------------------\n",
      "The Top Important Words:  school; elementary; skinner; springfield; teacher; student; students; principal; class; bart\n",
      "The Top title entities : \n",
      "\n",
      " Principal Hartly\n",
      " Meredith Milgram\n",
      " Mrs. Harvell\n",
      " Principal Sackett\n",
      " Lisa’s Classmate 7\n",
      "----------------------#####----------------------\n",
      "The Cluster number 5 and the number of words 2674\n",
      "----------------------#####----------------------\n",
      "The Top Important Words:  simpson; son; great; father; mother; daughter; abe; abraham; wife; husband\n",
      "The Top title entities : \n",
      "\n",
      " Simpson family\n",
      " Hortensia Stemple\n",
      " \"Happy\" Dinsdale\n",
      " Omar Stillman\n",
      " Great Family\n",
      "----------------------#####----------------------\n",
      "The Cluster number 6 and the number of words 1627\n",
      "----------------------#####----------------------\n",
      "The Top Important Words:  spuckler; cletus; brandine; children; mary; incest; cow; goldilocks; pete; harvester\n",
      "The Top title entities : \n",
      "\n",
      " Kyra Spuckler\n",
      " Pediculus Spuckler\n",
      " Zoe Spuckler\n",
      " Dara Spuckler\n",
      " Sascha Spuckler\n",
      "----------------------#####----------------------\n",
      "The Cluster number 7 and the number of words 4361\n",
      "----------------------#####----------------------\n",
      "The Top Important Words:  itchy; scratchy; van; houten; span; milhouse; land; quimby; font; kirk\n",
      "The Top title entities : \n",
      "\n",
      " Itchy & Scratchy Land Guard 2\n",
      " Itchy & Scratchy Land Guard 1\n",
      " Itchy & Scratchy Land Scientist 2\n",
      " Itchy & Scratchy Land Pilot\n",
      " Itchy & Scratchy Land clerk\n",
      "----------------------#####----------------------\n",
      "The Cluster number 8 and the number of words 3096\n",
      "----------------------#####----------------------\n",
      "The Top Important Words:  restaurant; food; fast; waiter; springfield; marge; homer; king; seething; diner\n",
      "The Top title entities : \n",
      "\n",
      " The Kabuli Palow\n",
      " Odd Ones\n",
      " Hamburger Heaven\n",
      " Der Krazy Kraut\n",
      " Two Guys From Kabul\n",
      "----------------------#####----------------------\n",
      "The Cluster number 9 and the number of words 2268\n",
      "----------------------#####----------------------\n",
      "The Top Important Words:  center; guard; knight; shadow; earthland; realms; dr; juliet; monroe; museum\n",
      "The Top title entities : \n",
      "\n",
      " Alf\n",
      " Warrior Marge\n",
      " Pig Man Wiggum\n",
      " Tauren Mel\n",
      " Warrior Comic Book Guy\n",
      "----------------------#####----------------------\n",
      "The Cluster number 10 and the number of words 3526\n",
      "----------------------#####----------------------\n",
      "The Top Important Words:  shop; country; globe; history; seen; retirement; castle; located; asia; springfield\n",
      "The Top title entities : \n",
      "\n",
      " Cambodia\n",
      " Colombia\n",
      " Chile\n",
      " Thailand\n",
      " Cameroon\n",
      "----------------------#####----------------------\n",
      "The Cluster number 11 and the number of words 1961\n",
      "----------------------#####----------------------\n",
      "The Top Important Words:  bouvier; selma; patty; gurney; great; jacqueline; marcel; eau; siblings; simpson\n",
      "The Top title entities : \n",
      "\n",
      " Jen Gurney\n",
      " Alfreda LeDoux\n",
      " Chester Bouvier\n",
      " Charlene Bouvier\n",
      " Arturo Bisque\n",
      "----------------------#####----------------------\n",
      "The Cluster number 12 and the number of words 3766\n",
      "----------------------#####----------------------\n",
      "The Top Important Words:  couch; gag; simpson; maggie; plot; appearances; character; season; family; marge\n",
      "The Top title entities : \n",
      "\n",
      " Rotoscoped couch gag\n",
      " Homer's Couch couch gag\n",
      " Paintbrush couch gag\n",
      " Lying Down Bart couch gag\n",
      " Monster Couch couch gag\n",
      "----------------------#####----------------------\n",
      "The Cluster number 13 and the number of words 4866\n",
      "----------------------#####----------------------\n",
      "The Top Important Words:  song; sung; lyrics; played; homer; performed; lisa; oh; love; written\n",
      "The Top title entities : \n",
      "\n",
      " Amore\n",
      " Corey Leak\n",
      " Ragtag Bunch of Mistfits\n",
      " G.I. Jane Musical\n",
      " Paul Blart Musical\n",
      "----------------------#####----------------------\n",
      "The Cluster number 14 and the number of words 5924\n",
      "----------------------#####----------------------\n",
      "The Top Important Words:  burns; charles; mr; plant; montgomery; nuclear; power; smithers; employee; springfield\n",
      "The Top title entities : \n",
      "\n",
      " Kathy\n",
      " Robot Workers\n",
      " Worker in Love 3\n",
      " Worker in Love 2\n",
      " Worker in Love 1\n",
      "----------------------#####----------------------\n",
      "The Cluster number 15 and the number of words 5989\n",
      "----------------------#####----------------------\n",
      "The Top Important Words:  homer; history; man; simpson; asked; lisa; bart; told; terrace; springfield\n",
      "The Top title entities : \n",
      "\n",
      " Homer's Lhasa Apso\n",
      " Nureen\n",
      " Marlin\n",
      " Stinking Fish Realty\n",
      " Red Barclay's truck\n",
      "----------------------#####----------------------\n",
      "The Cluster number 16 and the number of words 3379\n",
      "----------------------#####----------------------\n",
      "The Top Important Words:  parody; laughter; towne; centre; store; game; glenne; wars; board; history\n",
      "The Top title entities : \n",
      "\n",
      " Georgio Ourmoney\n",
      " Yahtzu\n",
      " Tiddlywonks\n",
      " Nouveau Bitch\n",
      " Neiman Mark-Up\n",
      "----------------------#####----------------------\n",
      "The Cluster number 17 and the number of words 5015\n",
      "----------------------#####----------------------\n",
      "The Top Important Words:  hair; wears; brown; shirt; blue; pink; white; appearance; red; description\n",
      "The Top title entities : \n",
      "\n",
      " Cool kid\n",
      " Lisa's Classmate 1\n",
      " Tyler's Brother\n",
      " Popular Girl 3\n",
      " Great Son\n",
      "----------------------#####----------------------\n",
      "The Cluster number 18 and the number of words 7114\n",
      "----------------------#####----------------------\n",
      "The Top Important Words:  american; actor; guest; born; simpsons; episode; starred; known; voiced; writer\n",
      "The Top title entities : \n",
      "\n",
      " Nick Bakay\n",
      " Ira Glass\n",
      " John Updike\n",
      " Billy Eichner\n",
      " Jordan Nagai\n",
      "----------------------#####----------------------\n",
      "The Cluster number 19 and the number of words 3807\n",
      "----------------------#####----------------------\n",
      "The Top Important Words:  springfield; store; located; mall; city; sells; street; district; hotel; capital\n",
      "The Top title entities : \n",
      "\n",
      " Just Rainsticks\n",
      " Gifts\n",
      " Hailstone's\n",
      " Beachwear\n",
      " Gifts (Airport)\n",
      "----------------------#####----------------------\n",
      "The Cluster number 20 and the number of words 4638\n",
      "----------------------#####----------------------\n",
      "The Top Important Words:  bob; sideshow; apu; mart; kwik; nahasapeemapetilon; manjula; springfield; prison; octuplets\n",
      "The Top title entities : \n",
      "\n",
      " Vesti la Giubba\n",
      " Behold The Lord High Executioner\n",
      " Bob's Victorian House\n",
      " Sideshow Blob\n",
      " Tambourine Bob\n",
      "----------------------#####----------------------\n"
     ]
    }
   ],
   "source": [
    "# Cluster with k=20, and explain!\n",
    "\n",
    "# YOUR CODE HERE\n",
    "centers, clusters, _ = spherical_kmeans(tfidf, initial_centers (tfidf, 20, 42), 100)\n",
    "explain(tfidf, vocabulary, titles, centers, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6865c494",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1e34779d3287fd399a82aca79ba5670",
     "grade": true,
     "grade_id": "cell-d39abf331ee8aac4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "with patch('__main__.most_important') as mock_1, patch('__main__.most_central') as mock_2, patch('__main__.print') as mock_3:\n",
    "    explain(tfidf, vocabulary, titles, tfidf[[0,1]].toarray(), np.arange(0,tfidf.shape[0])&1)\n",
    "    assert mock_1.called, \"You did not use most_important\"\n",
    "    assert mock_2.called, \"You did not use most_central\"\n",
    "    assert mock_3.called, \"You did not print\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

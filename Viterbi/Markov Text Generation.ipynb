{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02c23244",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All) to avoid typical problems with Jupyter notebooks. **Unfortunately, this does not work with Chrome right now, you will also need to reload the tab in Chrome afterwards**.\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\". Please put your name here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aec2eb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Aymane Hachcham\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9241c0d5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf88e159",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2d536d05fc4d46bfcaf1f25b188f1b73",
     "grade": false,
     "grade_id": "cell-5d2c3db986825336",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Text Generation with Markov Chains\n",
    "\n",
    "In this exercise, we want to make a Donald Trump fake tweet generator using a simple Markov chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e42dd79",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e095d2c603aacdee9e81e5c06715b947",
     "grade": false,
     "grade_id": "cell-3f1c36f9e42413a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the tweet data:\n",
    "import gzip, re, sys\n",
    "tweets = [[sys.intern(y) for y in re.split(r\"\\s\", x.strip())] for x in gzip.open(\"/data/tweets_realDonaldTrump_sanitized.txt.gz\", \"rt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26051aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Thank', 'you', 'Arkansas!', '#Trump2016', '#SuperTuesday'],\n",
       " ['Thank', 'you', 'Virginia!', '#Trump2016', '#SuperTuesday'],\n",
       " ['Thank', 'you', 'Alabama!', '#Trump2016', '#SuperTuesday'],\n",
       " ['Thank', 'you', 'Tennessee!', '#Trump2016', '#SuperTuesday'],\n",
       " ['Thank', 'you', 'Massachusetts!', '#Trump2016', '#SuperTuesday'],\n",
       " ['Thank', 'you', 'Georgia!', '#SuperTuesday', '#Trump2016'],\n",
       " ['Wow!',\n",
       "  'Thank',\n",
       "  'you',\n",
       "  'Louisville,',\n",
       "  'Kentucky!',\n",
       "  '',\n",
       "  '#VoteTrump',\n",
       "  'on',\n",
       "  '3/5/2016!',\n",
       "  'Lets',\n",
       "  '#MakeAmericaGreatAgain!',\n",
       "  'http://somelink.com/',\n",
       "  'http://someotherlink.com/'],\n",
       " ['Lets',\n",
       "  'go',\n",
       "  'America!',\n",
       "  'Get',\n",
       "  'out',\n",
       "  '&',\n",
       "  '#VoteTrump!',\n",
       "  '#Trump2016',\n",
       "  '#MakeAmericaGreatAgain!',\n",
       "  '#SuperTuesday',\n",
       "  'http://somelink.com/',\n",
       "  'http://someotherlink.com/'],\n",
       " ['MAKE', 'AMERICA', 'GREAT', 'AGAIN!'],\n",
       " ['Thank', 'you', 'Columbus,', 'Ohio!', 'http://somelink.com/']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the data:\n",
    "\n",
    "tweets[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8e60b9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8ca875d48601e58b3ec11ef1b849475e",
     "grade": false,
     "grade_id": "cell-a118be647ad3168f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Collect the necessary statistics for the Markov model\n",
    "\n",
    "We need the term frequencies to predict the next word given the previous 0...order words.\n",
    "\n",
    "Use `()` (empty tuple) as a start and stop token. Use tuples as keys in your maps.\n",
    "\n",
    "For the 0th order, this is simply the word frequency!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ca23fdfe",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "676995ce224852066ecbcfc0bd2d5a00",
     "grade": false,
     "grade_id": "cell-99d57eea729afd84",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Aggregate the data as necessary for Markov model of order 0...order\n",
    "def aggregate(tweets, order):\n",
    "    from collections import defaultdict, Counter\n",
    "    models = []\n",
    "    # As 0th order, use the first tokens only. \n",
    "    tokens = []\n",
    "    for tweet in tweets:\n",
    "        tokens.append(tweet[0])\n",
    "    counter = Counter(tokens)\n",
    "    \n",
    "    models.append({(): counter})\n",
    "    \n",
    "    for o in range(1, order+1):\n",
    "        model = {} # use tuple() -> word (or empty tuple)\n",
    "        \n",
    "        if o == 1:\n",
    "            # Code for the first order:\n",
    "            for tweet in tweets:\n",
    "                n_tokens = len(tweet)\n",
    "            \n",
    "                for index, key in enumerate(tweet):\n",
    "                    if n_tokens > (index + 1):\n",
    "                        word = tweet[index + 1]\n",
    "                    \n",
    "                        if key not in model:\n",
    "                            model[key] = [word]\n",
    "                        else:\n",
    "                            model[key].append(word)\n",
    "                    else:\n",
    "                        word = ()\n",
    "                        if key not in model:\n",
    "                            model[key] = [word]\n",
    "                        else:\n",
    "                            model[key].append(word)\n",
    "            \n",
    "            for k in model:\n",
    "                model[k] = dict(Counter(model[k]))\n",
    "            \n",
    "            models.append(model)\n",
    "        \n",
    "        else:\n",
    "            # Code for the second order:\n",
    "            for tweet in tweets:\n",
    "                n_tokens = len(tweet)\n",
    "    \n",
    "                for i, key1 in enumerate(tweet):  \n",
    "                    if n_tokens > i + 2:\n",
    "                        key2 = tweet[i + 1]\n",
    "                        word = tweet[i + 2]\n",
    "                        if (key1, key2) not in model:\n",
    "                            model[(key1, key2)] = [word]\n",
    "                        else:\n",
    "                            model[(key1, key2)].append(word)\n",
    "                    \n",
    "                    elif i + 2 == n_tokens:\n",
    "                        key2 = tweet[i + 1]\n",
    "                        word = ()\n",
    "                        if (key1, key2) not in model:\n",
    "                            model[(key1, key2)] = [word]\n",
    "                        else:\n",
    "                            model[(key1, key2)].append(word)\n",
    "                            \n",
    "            for k in model:\n",
    "                model[k] = dict(Counter(model[k]))\n",
    "            \n",
    "            models.append(model)\n",
    "       \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "555b076c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa502c5173b565dd5c311d1c5a062ee9",
     "grade": true,
     "grade_id": "cell-cc42f3c46e849c9d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#### AUTOMATIC TESTS\n",
    "_tmp = aggregate(tweets[:100], order=2)\n",
    "assert len(_tmp) == 3 and isinstance(_tmp, list), \"Wrong result\"\n",
    "assert all(isinstance(x, dict) for x in _tmp), \"Wrong result\"\n",
    "assert not () in _tmp[0][()], \"0th order must not include the end token\"\n",
    "assert sum(_tmp[0][()].values()) == 100, \"0th order incorrect.\"\n",
    "assert sum(sum(x.values()) for x in _tmp[1].values()) == sum(len(x) for x in tweets[:100]), \"1th order incomplete.\"\n",
    "assert sum(sum(x.values()) for x in _tmp[2].values()) == sum(len(x)-1 for x in tweets[:100]), \"2nd order incomplete.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b011a9d0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "202c56fb465a708b9de09610b26992d0",
     "grade": true,
     "grade_id": "cell-d12114dd97314f71",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#### Additional hidden AUTOMATIC TESTS\n",
    "del _tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a80363a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "823b1e7dbc272a6fe3f9519115025909",
     "grade": false,
     "grade_id": "cell-1d2df7ddb24aeb73",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ffce5ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.17 s, sys: 423 ms, total: 1.59 s\n",
      "Wall time: 1.59 s\n"
     ]
    }
   ],
   "source": [
    "%time model = aggregate(tweets, order=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "124f4108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Virginia! #Trump2016',\n",
       " 'you Arkansas!',\n",
       " 'Thank you',\n",
       " 'Virginia! #Trump2016',\n",
       " 'you Arkansas!',\n",
       " 'you Arkansas!',\n",
       " 'Thank you',\n",
       " 'Virginia! #Trump2016',\n",
       " '#Trump2016 #SuperTuesday']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testin the function how it should be:\n",
    "model = aggregate(tweets[:2], order=2)\n",
    "\n",
    "order = len(model) - 1\n",
    "\n",
    "w1 = random.choice([t for tweet in tweets[:2] for t in tweet])\n",
    "random_order = random.randrange(order)\n",
    "\n",
    "# print(max(model[1][w1], key=model[1][w1].get))\n",
    "\n",
    "f_t = []\n",
    "for i in range(10):\n",
    "    w1 = random.choice([t for tweet in tweets[:2] for t in tweet])\n",
    "    \n",
    "#     print(max(model[1][w1], key=model[1][w1].get))\n",
    "    \n",
    "    if max(model[1][w1], key=model[1][w1].get) == ():\n",
    "        continue\n",
    "    else:\n",
    "        w2 = w1 + ' ' + max(model[1][w1], key=model[1][w1].get) \n",
    "    \n",
    "    f_t.append(w2)\n",
    "\n",
    "f_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824fd206",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a319a745526da8fef508a48271803ac8",
     "grade": false,
     "grade_id": "cell-cb32b8c3ed1bba8b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Make Trump tweet again\n",
    "\n",
    "Lets make Trump tweet again.\n",
    "\n",
    "Write a function \"trump\" that randomly generates trumpesque garbage given the above model, by randomly sampling from the appropriate distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7300998b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "order = 2\n",
    "# random.choice[i for i in range(order)]\n",
    "\n",
    "random.randrange(order)\n",
    "\n",
    "# random.choice(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "2f9b17e4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b17fe87673c73f6cbe393f5388195b80",
     "grade": false,
     "grade_id": "cell-afe8e59e335032ef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def trump(model):\n",
    "    \"\"\"Generate Trumpesque nonsense from a trained Markov model\"\"\"\n",
    "    import random\n",
    "    order = len(model) - 1\n",
    "    output = []\n",
    "    for i in range(0, 100): # enforce a max length 100, in case your stopping does not work\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        random_order = random.randrange(order)\n",
    "        w1 = random.choice([t for tweet in tweets[:2] for t in tweet])\n",
    "        if w1 in model[random_order]:\n",
    "            if max(model[random_order][w1], key=model[random_order][w1].get) == ():\n",
    "                continue\n",
    "            else:\n",
    "                next_word = w1 + ' ' + max(model[random_order][w1], key=model[random_order][w1].get)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        output.append(next_word)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "97a85009",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf4fb90f40c3ebef113750db6eaca339",
     "grade": true,
     "grade_id": "cell-d7acff8452df539e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Does not work right.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [200]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m _tmp \u001b[38;5;241m=\u001b[39m aggregate(tweets[:\u001b[38;5;241m100\u001b[39m], order\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      3\u001b[0m _tmp \u001b[38;5;241m=\u001b[39m [trump(_tmp) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m)]\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://somelink.com/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m _tmp), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoes not work right.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#MakeAmericaGreatAgain\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m _tmp), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoes not work right.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28many\u001b[39m(x \u001b[38;5;129;01min\u001b[39;00m tweets[:\u001b[38;5;241m100\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m _tmp), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome tweet must be reproduced\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Does not work right."
     ]
    }
   ],
   "source": [
    "#### AUTOMATIC TESTS\n",
    "_tmp = aggregate(tweets[:100], order=2)\n",
    "_tmp = [trump(_tmp) for x in range(100)]\n",
    "assert any('http://somelink.com/' in x for x in _tmp), \"Does not work right.\"\n",
    "assert any('#MakeAmericaGreatAgain' in x for x in _tmp), \"Does not work right.\"\n",
    "assert any(x in tweets[:100] for x in _tmp), \"Some tweet must be reproduced\"\n",
    "assert any(x not in tweets[:100] for x in _tmp), \"Some tweet must be fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8552a6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8299c514bb3af054ffd8984e0324343",
     "grade": true,
     "grade_id": "cell-8c116fea73afa671",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#### Additional hidden AUTOMATIC TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea645fac",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71f6bfb95308108871d05a11e153d60e",
     "grade": true,
     "grade_id": "cell-1f89f2f0ecdced63",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#### Additional hidden AUTOMATIC TESTS\n",
    "del _tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0b269a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "048a1c87ed3e7b2985870c75d8460dcb",
     "grade": true,
     "grade_id": "cell-77e0ce6a481cac94",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#### Additional hidden AUTOMATIC TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d2a913",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc400610744b7711fc8386f4dbacec54",
     "grade": false,
     "grade_id": "cell-c06748edbebbe1a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Make Donald Trump tweet garbage again\n",
    "\n",
    "Lets make Donald Trump tweet again. Generate some Trumpesque nonsense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5daa3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(*trump(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdf30a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

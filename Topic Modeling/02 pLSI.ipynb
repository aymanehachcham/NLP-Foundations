{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64c6a8b1",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All) to avoid typical problems with Jupyter notebooks. **Unfortunately, this does not work with Chrome right now, you will also need to reload the tab in Chrome afterwards**.\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\". Please put your name here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f62fb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Aymane Hachcham\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4eeb6f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc15fc1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ced10babba5dd187ba80f65774dd05f",
     "grade": false,
     "grade_id": "cell-dddd9b472cdda421",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Probabilistic Latent Semantic Indexing\n",
    "\n",
    "Now we will implement latent semantic indexing (LSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43686fed",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6dd047a5f2cf5fdc2ca134bcc7fecd40",
     "grade": false,
     "grade_id": "cell-cf0a1f8d45f50016",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Load the input data - do not modify\n",
    "import json, gzip, numpy as np\n",
    "raw = json.load(gzip.open(\"/data/simpsonswiki.json.gz\", \"rt\", encoding=\"utf-8\"))\n",
    "titles, texts, classes = [x[\"title\"] for x in raw], [x[\"text\"] for x in raw], [x[\"c\"] for x in raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7198d845",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "264d6f477689c6087be9840a47f0289e",
     "grade": true,
     "grade_id": "cell-efe7fecd64a3b68c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### This cell reduces the data set size for the autograder tests - do not modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a878ace3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c5f701671ffe89035fb4e56423452cb",
     "grade": false,
     "grade_id": "cell-dafc634f8c46b474",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Vectorize the text - do not modify\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvect = CountVectorizer(stop_words=\"english\", min_df=5)\n",
    "counts = cvect.fit_transform(texts)\n",
    "vocabulary = cvect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "157cefc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14143</th>\n",
       "      <th>14144</th>\n",
       "      <th>14145</th>\n",
       "      <th>14146</th>\n",
       "      <th>14147</th>\n",
       "      <th>14148</th>\n",
       "      <th>14149</th>\n",
       "      <th>14150</th>\n",
       "      <th>14151</th>\n",
       "      <th>14152</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10121</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10122</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10123</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10124</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10125</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10126 rows Ã— 14153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6      7      8      9      \\\n",
       "0          0      0      0      0      0      0      0      0      0      0   \n",
       "1          0      0      0      0      0      0      0      0      0      0   \n",
       "2          0      0      0      0      0      0      0      0      0      1   \n",
       "3          0      0      0      0      0      0      0      0      0      0   \n",
       "4          0      0      0      0      0      0      0      0      0      0   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "10121      0      0      0      0      0      0      0      0      0      0   \n",
       "10122      0      0      0      0      0      0      0      0      0      0   \n",
       "10123      0      0      0      0      0      0      0      0      0      0   \n",
       "10124      0      0      0      0      0      0      0      0      0      0   \n",
       "10125      0      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "       ...  14143  14144  14145  14146  14147  14148  14149  14150  14151  \\\n",
       "0      ...      0      0      0      0      0      0      0      0      0   \n",
       "1      ...      0      0      0      0      0      0      0      0      0   \n",
       "2      ...      0      0      0      0      0      0      0      0      0   \n",
       "3      ...      0      0      0      0      0      0      0      0      0   \n",
       "4      ...      0      0      0      0      0      0      0      0      0   \n",
       "...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "10121  ...      0      0      0      0      0      0      0      0      0   \n",
       "10122  ...      0      0      0      0      0      0      0      0      0   \n",
       "10123  ...      0      0      0      0      0      0      0      0      0   \n",
       "10124  ...      0      0      0      0      0      0      0      0      0   \n",
       "10125  ...      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "       14152  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "10121      0  \n",
       "10122      0  \n",
       "10123      0  \n",
       "10124      0  \n",
       "10125      0  \n",
       "\n",
       "[10126 rows x 14153 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame.sparse.from_spmatrix(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4af627",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c0a9ec6fdd6e31f5bd8c6169e2a83a0f",
     "grade": false,
     "grade_id": "cell-f50d41a9220315d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Explore your result\n",
    "\n",
    "Explore the result: write a function to determine the most important words for each factor, and the most relevant documents.\n",
    "\n",
    "**COPY your code from the first file here** (this is a rare case where copying is okay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dcf971e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d81e82f2aaf8dedf2e57743c005ffe4",
     "grade": false,
     "grade_id": "cell-c3a23922942e74ed",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def most_important(vocabulary, factor, k=10):\n",
    "    \"\"\"Most important words for each factor\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    indices_max_values = np.argpartition(factor, -k)[-k:]\n",
    "    list_vocabs = [vocabulary[i] for i in indices_max_values]\n",
    "    return list_vocabs\n",
    "\n",
    "def most_relevant(assignment, k=5):\n",
    "    \"\"\"Most relevant documents for each factor (return document indexes)\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    indices_max_values = np.argpartition(assignment, -k)[-k:]\n",
    "    return indices_max_values\n",
    "\n",
    "def explain(vocabulary, titles=None, classes=None, factors=None, assignment=None, weights=None):\n",
    "    \"\"\"Print an explanation for each factor.\n",
    "       If weights is None, use the relative share of the assignment weights.\n",
    "       Print the ARI when assigning each document to its maximum only.\"\"\"\n",
    "    from sklearn.metrics import adjusted_rand_score\n",
    "    for i, f in enumerate(factors):\n",
    "        print('For the Factor: {}, these are the following results'.format(i))\n",
    "        important_vocabs = most_important(vocabulary, f)\n",
    "        print('The most relevant words in this topic are: ')\n",
    "        print('-------------------------------------------------------')\n",
    "        print('\\n')\n",
    "        print(important_vocabs)\n",
    "        important_docs = most_relevant(assignment)\n",
    "        print('-------------------------------------------------------')\n",
    "        print('\\n')\n",
    "        print('The most relevant documents belonging to this topic are: ')\n",
    "        print([titles[i] for fact in important_docs for i in fact])\n",
    "        print('\\n')\n",
    "        print('Their respective classes are ')\n",
    "        print([classes[i] for fact in important_docs for i in fact])\n",
    "        if weights is not None:\n",
    "            factor_weight = weights[i]\n",
    "            print('-------------------------------------------------------')\n",
    "            print('\\n')\n",
    "            print('The Weight factor for this topic is {}'.format(factor_weight))\n",
    "        print('#################################################################')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4f0ef9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fab800476249bd37078f2d8bf89667f2",
     "grade": false,
     "grade_id": "cell-00e0e4e0fa7cf5df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implement probabilistic Latent Semantic Indexing\n",
    "\n",
    "Implement pLSI using the non-negative matrix factorization function of sklearn. Make sure to choose appropriate parameters to use KL divergence -- it is not sufficient to use defaults!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a72eead9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63665feee65836d1e81f43397ef49174",
     "grade": false,
     "grade_id": "cell-6a46ed0ac1bb4018",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Implement pLSI here using NMF\n",
    "# Can only use raw term counts, because it is a probabilistic graphical model\n",
    "def plsi(counts, k):\n",
    "    \"\"\"Probabilistic Latent Semantic Indexing. Return the factors and document assignment\"\"\"\n",
    "    from sklearn.decomposition import NMF\n",
    "    model = NMF(k, random_state=1, beta_loss=\"kullback-leibler\", solver=\"mu\", max_iter=1000, l1_ratio=0.5)\n",
    "\n",
    "    # Train an NMF model for given Document Term Matrix 'V':\n",
    "    # Extract the document-topic matrix 'W'\n",
    "    assignment = model.fit_transform(counts)\n",
    "    factors = model.components_\n",
    "\n",
    "    return factors, assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4726edbb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "acf5ab3248916a0a99b32b35dbf3f632",
     "grade": true,
     "grade_id": "cell-8493a4259f377dbe",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### Automatic tests. You do not need to understand or modify this code.\n",
    "from unittest.mock import patch\n",
    "with patch('gensim.models.lsimodel.LsiModel') as mock_2:\n",
    "    _tmp = plsi(counts, 2)\n",
    "    assert len(_tmp) == 2, \"Incomplete result\"\n",
    "    assert _tmp[0].shape == (2, counts.shape[1]), \"Factor shape is not correct.\"\n",
    "    assert _tmp[1].shape == (counts.shape[0], 2), \"Assignment shape is not correct.\"\n",
    "    assert not mock_2.called, \"You were supposed to use sklearn here, not gensim.\"\n",
    "del _tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f0a08ce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e020359de984836220e0684f52fad3e7",
     "grade": true,
     "grade_id": "cell-0586d9e76933c1bb",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### This cell contains additional tests. You do not need to modify this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be9d3543",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83ec05ef5a096dad41236ded4cd68f1d",
     "grade": false,
     "grade_id": "cell-8b2811a2d3403995",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the Factor: 0, these are the following results\n",
      "The most relevant words in this topic are: \n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "['house', 'family', 'moe', 'tells', 'says', 'episode', 'lisa', 'marge', 'bart', 'homer']\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "The most relevant documents belonging to this topic are: \n",
      "['Bart Jumps', 'Burp Contest', 'Good Night', 'Babysitting Maggie', 'The Pacifier', 'Watching Television', 'Watching Television', 'Burp Contest', 'Bart Jumps', 'Babysitting Maggie', 'The Pacifier', 'Good Night', 'Good Night', 'Burp Contest', 'Bart Jumps', 'Babysitting Maggie', 'The Pacifier', 'Watching Television', 'Burp Contest', 'Bart Jumps', 'Watching Television', 'Babysitting Maggie', 'The Pacifier', 'Good Night', 'Watching Television', 'Burp Contest', 'Bart Jumps', 'Babysitting Maggie', 'The Pacifier', 'Good Night']\n",
      "\n",
      "\n",
      "Their respective classes are \n",
      "['Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes']\n",
      "#################################################################\n",
      "For the Factor: 1, these are the following results\n",
      "The most relevant words in this topic are: \n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "['town', 'new', 'springfield', 'simpsons', 'city', 'simpson', 'apu', 'history', 'moe', 'homer']\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "The most relevant documents belonging to this topic are: \n",
      "['Bart Jumps', 'Burp Contest', 'Good Night', 'Babysitting Maggie', 'The Pacifier', 'Watching Television', 'Watching Television', 'Burp Contest', 'Bart Jumps', 'Babysitting Maggie', 'The Pacifier', 'Good Night', 'Good Night', 'Burp Contest', 'Bart Jumps', 'Babysitting Maggie', 'The Pacifier', 'Watching Television', 'Burp Contest', 'Bart Jumps', 'Watching Television', 'Babysitting Maggie', 'The Pacifier', 'Good Night', 'Watching Television', 'Burp Contest', 'Bart Jumps', 'Babysitting Maggie', 'The Pacifier', 'Good Night']\n",
      "\n",
      "\n",
      "Their respective classes are \n",
      "['Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes']\n",
      "#################################################################\n",
      "For the Factor: 2, these are the following results\n",
      "The most relevant words in this topic are: \n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "['seen', 'history', 'elementary', 'nelson', 'skinner', 'milhouse', 'springfield', 'bart', 'lisa', 'school']\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "The most relevant documents belonging to this topic are: \n",
      "['Bart Jumps', 'Burp Contest', 'Good Night', 'Babysitting Maggie', 'The Pacifier', 'Watching Television', 'Watching Television', 'Burp Contest', 'Bart Jumps', 'Babysitting Maggie', 'The Pacifier', 'Good Night', 'Good Night', 'Burp Contest', 'Bart Jumps', 'Babysitting Maggie', 'The Pacifier', 'Watching Television', 'Burp Contest', 'Bart Jumps', 'Watching Television', 'Babysitting Maggie', 'The Pacifier', 'Good Night', 'Watching Television', 'Burp Contest', 'Bart Jumps', 'Babysitting Maggie', 'The Pacifier', 'Good Night']\n",
      "\n",
      "\n",
      "Their respective classes are \n",
      "['Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes']\n",
      "#################################################################\n",
      "For the Factor: 3, these are the following results\n",
      "The most relevant words in this topic are: \n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "['character', 'episode', 'simpsons', 'burns', 'smithers', 'simpson', 'bouvier', 'series', 'great', 'mr']\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "The most relevant documents belonging to this topic are: \n",
      "['Bart Jumps', 'Burp Contest', 'Good Night', 'Babysitting Maggie', 'The Pacifier', 'Watching Television', 'Watching Television', 'Burp Contest', 'Bart Jumps', 'Babysitting Maggie', 'The Pacifier', 'Good Night', 'Good Night', 'Burp Contest', 'Bart Jumps', 'Babysitting Maggie', 'The Pacifier', 'Watching Television', 'Burp Contest', 'Bart Jumps', 'Watching Television', 'Babysitting Maggie', 'The Pacifier', 'Good Night', 'Watching Television', 'Burp Contest', 'Bart Jumps', 'Babysitting Maggie', 'The Pacifier', 'Good Night']\n",
      "\n",
      "\n",
      "Their respective classes are \n",
      "['Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes']\n",
      "#################################################################\n",
      "For the Factor: 4, these are the following results\n",
      "The most relevant words in this topic are: \n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "['simpsons', 'marge', 'season', 'maggie', 'gag', 'couch', 'simpson', 'family', 'lisa', 'song']\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "The most relevant documents belonging to this topic are: \n",
      "['Bart Jumps', 'Burp Contest', 'Good Night', 'Babysitting Maggie', 'The Pacifier', 'Watching Television', 'Watching Television', 'Burp Contest', 'Bart Jumps', 'Babysitting Maggie', 'The Pacifier', 'Good Night', 'Good Night', 'Burp Contest', 'Bart Jumps', 'Babysitting Maggie', 'The Pacifier', 'Watching Television', 'Burp Contest', 'Bart Jumps', 'Watching Television', 'Babysitting Maggie', 'The Pacifier', 'Good Night', 'Watching Television', 'Burp Contest', 'Bart Jumps', 'Babysitting Maggie', 'The Pacifier', 'Good Night']\n",
      "\n",
      "\n",
      "Their respective classes are \n",
      "['Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes']\n",
      "#################################################################\n",
      "For the Factor: 5, these are the following results\n",
      "The most relevant words in this topic are: \n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "['movie', 'character', 'clown', 'bob', 'ned', 'episode', 'sideshow', 'simpsons', 'flanders', 'krusty']\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "The most relevant documents belonging to this topic are: \n",
      "['Bart Jumps', 'Burp Contest', 'Good Night', 'Babysitting Maggie', 'The Pacifier', 'Watching Television', 'Watching Television', 'Burp Contest', 'Bart Jumps', 'Babysitting Maggie', 'The Pacifier', 'Good Night', 'Good Night', 'Burp Contest', 'Bart Jumps', 'Babysitting Maggie', 'The Pacifier', 'Watching Television', 'Burp Contest', 'Bart Jumps', 'Watching Television', 'Babysitting Maggie', 'The Pacifier', 'Good Night', 'Watching Television', 'Burp Contest', 'Bart Jumps', 'Babysitting Maggie', 'The Pacifier', 'Good Night']\n",
      "\n",
      "\n",
      "Their respective classes are \n",
      "['Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes', 'Episodes']\n",
      "#################################################################\n"
     ]
    }
   ],
   "source": [
    "# Explore your result. These must be meaningful topics!\n",
    "plsi_factors, plsi_assignment = plsi(counts, 6)\n",
    "explain(vocabulary, titles, classes, plsi_factors, plsi_assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75563fa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33abcbaa84ed83cca750145aa20b9cca",
     "grade": true,
     "grade_id": "cell-cd45412a261736bb",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### This cell contains additional tests. You do not need to modify this cell."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

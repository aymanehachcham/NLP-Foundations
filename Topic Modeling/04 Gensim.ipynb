{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9d631d0",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All) to avoid typical problems with Jupyter notebooks. **Unfortunately, this does not work with Chrome right now, you will also need to reload the tab in Chrome afterwards**.\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\". Please put your name here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76007a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Aymane Hachcham\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504bb5f3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc15fc1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bdeba1289ceafcbd2ac6a9fda4541604",
     "grade": false,
     "grade_id": "cell-dddd9b472cdda421",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Latent Dirichlet Allocation\n",
    "\n",
    "Now we will use latent dirichlet allocation\n",
    "\n",
    "**Important notice:** the \"Validate\" function might timeout at 30 or 60 seconds.\n",
    "We intend to have the actual autograding later run with higher tolerance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43686fed",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6dd047a5f2cf5fdc2ca134bcc7fecd40",
     "grade": false,
     "grade_id": "cell-cf0a1f8d45f50016",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Load the input data - do not modify\n",
    "import json, gzip, numpy as np\n",
    "raw = json.load(gzip.open(\"/data/simpsonswiki.json.gz\", \"rt\", encoding=\"utf-8\"))\n",
    "titles, texts, classes = [x[\"title\"] for x in raw], [x[\"text\"] for x in raw], [x[\"c\"] for x in raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8097cceb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b793ce9e723433337533da3458b9ed4",
     "grade": true,
     "grade_id": "cell-6189bc2b35582680",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### This cell reduces the data set size for the autograder tests - do not modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a878ace3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c5f701671ffe89035fb4e56423452cb",
     "grade": false,
     "grade_id": "cell-dafc634f8c46b474",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Vectorize the text - do not modify\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvect = CountVectorizer(stop_words=\"english\", min_df=5)\n",
    "counts = cvect.fit_transform(texts)\n",
    "vocabulary = cvect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4af627",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "83fa804c6b440ec025ba3d6b1f99137d",
     "grade": false,
     "grade_id": "cell-f50d41a9220315d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Explore your result\n",
    "\n",
    "Explore the result: write a function to determine the most important words for each factor, and the most relevant documents.\n",
    "\n",
    "**COPY your code from the first file here** (one of the rare cases where copying is okay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dcf971e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d81e82f2aaf8dedf2e57743c005ffe4",
     "grade": false,
     "grade_id": "cell-c3a23922942e74ed",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def most_important(vocabulary, factor, k=10):\n",
    "    \"\"\"Most important words for each factor\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    indices_max_values = np.argpartition(factor, -k)[-k:]\n",
    "    list_vocabs = [vocabulary[i] for i in indices_max_values]\n",
    "    return list_vocabs\n",
    "\n",
    "def most_relevant(assignment, k=5):\n",
    "    \"\"\"Most relevant documents for each factor (return document indexes)\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    indices_max_values = np.argpartition(assignment, -k)[-k:]\n",
    "    return indices_max_values\n",
    "\n",
    "def explain(vocabulary, titles, classes, factors, assignment, weights=None):\n",
    "    \"\"\"Print an explanation for each factor.\n",
    "       If weights is None, use the relative share of the assignment weights.\n",
    "       Print the ARI when assigning each document to its maximum only.\"\"\"\n",
    "    from sklearn.metrics import adjusted_rand_score\n",
    "    # YOUR CODE HERE\n",
    "    for i, f in enumerate(factors):\n",
    "        print('For the Factor: {}, these are the following results'.format(i))\n",
    "        important_vocabs = most_important(vocabulary, f)\n",
    "        print('The most relevant words in this topic are: ')\n",
    "        print('-------------------------------------------------------')\n",
    "        print('\\n')\n",
    "        print(important_vocabs)\n",
    "        important_docs = most_relevant(assignment)\n",
    "        print('-------------------------------------------------------')\n",
    "        print('\\n')\n",
    "        print('The most relevant documents belonging to this topic are: ')\n",
    "        print([titles[i] for fact in important_docs for i in fact])\n",
    "        print('\\n')\n",
    "        print('Their respective classes are ')\n",
    "        print([classes[i] for fact in important_docs for i in fact])\n",
    "        if weights is not None:\n",
    "            factor_weight = weights[i]\n",
    "            print('-------------------------------------------------------')\n",
    "            print('\\n')\n",
    "            print('The Weight factor for this topic is {}'.format(factor_weight))\n",
    "        print('#################################################################')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542f1077",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "644e3639fd1d5bb977268bb1c8435798",
     "grade": false,
     "grade_id": "cell-a181cb9aedcb19d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## LDA with Gensim\n",
    "\n",
    "The `gensim` package contains more powerful implementations of LDA.\n",
    "\n",
    "To use these, you will need to convert the scipy data structures using `Scipy2Corpus`.\n",
    "\n",
    "For LDA, use an asymmetric topic prior. Use `chunksize=128, passes=2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abacabed",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3614d33647b236b8e2a9230566883fc2",
     "grade": true,
     "grade_id": "cell-1c0727f1f9288094",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Enable logging in Gensim - no need to modify\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94f7e492",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "afa9583152fafa6897044645750a91b7",
     "grade": false,
     "grade_id": "cell-30404fd9acaa2795",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Convert the corpus and vocabulary as needed for gensim here!\n",
    "corpus = None\n",
    "id2word = None\n",
    "\n",
    "from gensim.matutils import Scipy2Corpus\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "corpus = Scipy2Corpus(counts)\n",
    "id2word = dict([(i, s) for i, s in enumerate(vocabulary)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cbd1a25",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42e0d0a392d500b0273b69486d4f8336",
     "grade": true,
     "grade_id": "cell-84baffc8cd6b77a2",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests. You do not need to understand or modify this code.\n",
    "assert isinstance(id2word, dict), \"Not a dictionary\"\n",
    "assert len(id2word) == len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d145387",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "047884e38bd7a07bfc0395e97002f46e",
     "grade": false,
     "grade_id": "cell-7af6a457c2c91f01",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Use Gensim LDA here with an asymmetric prior!\n",
    "def gensim_lda(counts, id2word, k):\n",
    "    \"\"\"Latent Dirichlet Allocation. Return the factors and document assignment\"\"\"\n",
    "    from gensim.models.ldamodel import LdaModel\n",
    "    from gensim.matutils import corpus2dense # for return\n",
    "    # YOUR CODE HERE\n",
    "    lda_model = LdaModel(counts, num_topics=k, id2word=id2word)\n",
    "    topics_terms = lda_model.state.get_lambda()\n",
    "\n",
    "    #convert estimates to probability (sum equals to 1 per topic)\n",
    "    factors = np.apply_along_axis(lambda x: x/x.sum(),1,topics_terms)\n",
    "\n",
    "    return factors, assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44fd12e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97bda0230f48d7494e22cf25260ed23c",
     "grade": false,
     "grade_id": "cell-c1de51d57cdd42fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "glda_factors, glda_assignment = gensim_lda(counts, id2word, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a942ea5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b8705cdba8a3c61907af8fa1eb003b6",
     "grade": false,
     "grade_id": "cell-f388b3d5a8b7eee9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Explore your result. These must be meaningful topics!\n",
    "explain(vocabulary, titles, classes, glda_factors, glda_assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362004e4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e087d3d20aed1ce9ec47ad21f2c3b54f",
     "grade": true,
     "grade_id": "cell-1ad2c1abf2b8299a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests. You do not need to understand or modify this code.\n",
    "assert glda_factors.shape == (6, counts.shape[1]), \"Factor shape is not correct.\"\n",
    "assert glda_assignment.shape == (counts.shape[0], 6), \"Assignment shape is not correct.\"\n",
    "assert abs(glda_factors.sum()-6)<1e-6, \"Topic word matrix are not probabilities.\"\n",
    "# assert abs(glda_assignment.sum()-counts.shape[0])<1e-6, \"Document topic matrix are not probabilities.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa1ea1a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e801a1fc717da6718df399854d45797",
     "grade": true,
     "grade_id": "cell-6a175fff170db567",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### This cell contains additional tests. You do not need to modify this cell."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

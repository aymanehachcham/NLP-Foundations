{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7272f73c",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All) to avoid typical problems with Jupyter notebooks. **Unfortunately, this does not work with Chrome right now, you will also need to reload the tab in Chrome afterwards**.\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\". Please put your name here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2528216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Aymane Hachcham\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5107cb6d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af978821",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a538ff70e9b372ac6350bc77916fedc6",
     "grade": false,
     "grade_id": "cell-bcb31d7602ebd96f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Explore pre-trained word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6f78129",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31613fd0dd9efead87be0574c3de6e22",
     "grade": false,
     "grade_id": "cell-dee6afea1a8b3e81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Load the input data - do not modify\n",
    "import json, gzip, numpy as np\n",
    "raw = json.load(gzip.open(\"/data/simpsonswiki.json.gz\", \"rt\", encoding=\"utf-8\"))\n",
    "titles, texts, classes = [x[\"title\"] for x in raw], [x[\"text\"] for x in raw], [x[\"c\"] for x in raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc78cda0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "773815b9df268f7bdf2da03fd253410f",
     "grade": false,
     "grade_id": "cell-26686ad8010282a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Load the pretrained word2vec model from Google\n",
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load(\"/data/w2v-google-news.wordvectors\", mmap=\"r\")\n",
    "model.fill_norms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78d186f8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "355cbddec82145e8dc21f9c5eaa91241",
     "grade": false,
     "grade_id": "cell-4b66b73ca48e503f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Find the 10 most similar words to the \"Simpsons\"\n",
    "most_simpsons = None # words only\n",
    "\n",
    "# YOUR CODE HERE\n",
    "most_simpsons = [item[0] for item in model.most_similar('Simpsons', topn=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dab0cfe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa9d45c0840113bbea88b0f1ead7d99a",
     "grade": true,
     "grade_id": "cell-a82b38362043c40b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Automatic unit tests, no need to modify/study this.\n",
    "assert len(most_simpsons) == 10\n",
    "assert isinstance(most_simpsons[0], str)\n",
    "assert not \"paris_hilton\" in most_simpsons\n",
    "assert \"Simpsons_Movie\" in most_simpsons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6144c43",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "28fbc5b6117ea6ba2a5d07996f360172",
     "grade": false,
     "grade_id": "cell-9b8b23b8f56ec84b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Verify the classic king-queen example\n",
    "\n",
    "Verify that \"King - Man + Woman = Queen\", using the built-in function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dff5fa04",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "732799a2d003423258b9240368d257e2",
     "grade": false,
     "grade_id": "cell-ebb3309feb5feaa6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "most_kmw = None # 10 nearest words to \"king-man+woman\" using the gensim API\n",
    "\n",
    "# Finding the top ten most similar words to the combination: King-Man + Woman\n",
    "most_kmw = [item[0] for item in model.most_similar(positive=['king', 'woman'], negative=['man'], topn=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc2461c5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a179df1a85029a040ff74488d6d1e2ae",
     "grade": true,
     "grade_id": "cell-092cc1f5afec92da",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Automatic unit tests, no need to modify/study this.\n",
    "assert most_kmw[0] == \"queen\" or most_kmw[0][0] == \"queen\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392dbf67",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e1d64d4f11eea9e8c9f5f50a7d00552",
     "grade": false,
     "grade_id": "cell-84df6962b87b6de3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Try using Euclidean geometry\n",
    "\n",
    "Get the vectors for king, man, queen, and woman.\n",
    "\n",
    "Compute king-man+woman, and compute the distances to each of above four words. What word is closest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "774a02c6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f91c2dc9d2cf94aabc1bde6768a045b6",
     "grade": false,
     "grade_id": "cell-25bc6cf55e35694f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector of All distances:[1.727951, 3.7211041, 2.2986577, 3.2687893]\n"
     ]
    }
   ],
   "source": [
    "king, man, queen, woman = None, None, None, None # get the word vectors\n",
    "\n",
    "# Get the vectors for the 4 above words:\n",
    "king = model['king']\n",
    "man = model['man']\n",
    "queen = model['queen']\n",
    "woman = model['woman']\n",
    "\n",
    "king_man_women = king - man + woman\n",
    "\n",
    "# Calculate the Euclidean Distance using Numpy:\n",
    "import numpy as np\n",
    "\n",
    "all_distances = [np.linalg.norm(king_man_women - vect) for vect in [king, man, queen, woman]]\n",
    "\n",
    "# all_distances = []\n",
    "# for vect in [king, man, queen, woman]:\n",
    "#     euclidean_dist = np.linalg.norm(king_man_women - vect)\n",
    "#     all_distances.append(euclidean_dist)\n",
    "\n",
    "print('Vector of All distances:{}'.format(all_distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "841d05d4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d28f62c04e7b25400b41bd125600f65d",
     "grade": false,
     "grade_id": "cell-d99faae80decac74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance(king - man + woman, king) = 1.72795\n",
      "distance(king - man + woman, man) = 3.72110\n",
      "distance(king - man + woman, woman) = 3.26879\n",
      "distance(king - man + woman, queen) = 2.29866\n"
     ]
    }
   ],
   "source": [
    "target = king - man + woman\n",
    "for word, vec in [(\"king\", king), (\"man\", man), (\"woman\", woman), (\"queen\", queen)]:\n",
    "    score = np.sqrt(((target - vec)**2).sum())\n",
    "    print(\"distance(king - man + woman, %s) = %.5f\" % (word, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "351a4dab",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7480109aafe1031402dd7305f7a87f79",
     "grade": true,
     "grade_id": "cell-177d82c5790a717e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c695995",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f96b1f124e5cc716eb9e4351fdb2a2a6",
     "grade": false,
     "grade_id": "cell-c7729f1bb3a15d2d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Document representations\n",
    "\n",
    "Represent each document as the average word2vec vector of all words present in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6ce8187",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "74b863676d0a4eb8e37298131c73de00",
     "grade": false,
     "grade_id": "cell-c6994e3344916fc4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "document_vectors = np.zeros((len(titles), 300))\n",
    "from gensim.utils import tokenize\n",
    "for i, (title, text) in enumerate(zip(titles, texts)):\n",
    "    tokens = tokenize(title + \"\\n\" + text)\n",
    "    \n",
    "    # For each doc we assemble all words that exist in the model and create the mean vector out of them:\n",
    "    document_vectors[i] = np.mean(model[[word for word in list(set(tokens)) if word in model.key_to_index]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b66da2fa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e89f4792dc92cf0c9136d2f7e6dad963",
     "grade": true,
     "grade_id": "cell-3eace97c92a00a71",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Automatic unit tests, no need to modify/study this.\n",
    "assert document_vectors.shape == (len(titles), 300)\n",
    "assert np.abs(document_vectors).sum(axis=0).min() > 0, \"Some vector not initialized?\"\n",
    "assert np.abs(document_vectors).sum(axis=1).min() > 0, \"Some vector not initialized?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3183bd52",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0951d95adb7a6cb7e83cc6a504f0e9c2",
     "grade": false,
     "grade_id": "cell-45f0a36afb2bcb53",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Find the document with the shortest vector\n",
    "\n",
    "Note: this likely will be one of the longer documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11b8ce2a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33505adbc09b6720585df9b5d5dc542f",
     "grade": false,
     "grade_id": "cell-e7557f718c53d79a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Üter Zörker 2197\n"
     ]
    }
   ],
   "source": [
    "shortest = None # Document number of the document with the shortest vector\n",
    "\n",
    "# YOUR CODE HERE\n",
    "lengths = []\n",
    "from gensim.utils import tokenize\n",
    "for i, text in enumerate(texts):\n",
    "    # Tokenize first:\n",
    "    tokens = tokenize(text)\n",
    "    doc = [word for word in list(tokens) if word in model.key_to_index]\n",
    "    lengths.append(len(doc))\n",
    "\n",
    "shortest = lengths[min(lengths)]\n",
    "\n",
    "print(titles[shortest], len(texts[shortest]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77cde03c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "286cf381e59924d166951edeb81bce33",
     "grade": true,
     "grade_id": "cell-f5165975e620043a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden unit tests for grading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19642b05",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b5fa6099f1e3dccf8745fae9c933ceb4",
     "grade": false,
     "grade_id": "cell-cff39854c57f4357",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Find the two most similar documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebdc7e27",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6007574a7ed9f78e5cf2b8667ebf0f62",
     "grade": false,
     "grade_id": "cell-777c84fc5c8a7e61",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "similarity_matrix = None\n",
    "\n",
    "# Using Cosine similarity:\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculate the cosine similarity matrix:\n",
    "similarity_matrix = cosine_similarity(document_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e723c0c5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44166357a9e73d89c09375966a326511",
     "grade": true,
     "grade_id": "cell-168c9252a6260b94",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Automatic tests (no points)\n",
    "assert similarity_matrix.shape == (len(titles), len(titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a57e552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower triangular part of the matrix:\n",
    "lower_similarity_matrix = np.tril(similarity_matrix, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71d3a004",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "340ba675b85b33e2e7764a5b7aa16f45",
     "grade": false,
     "grade_id": "cell-36f8e0ba4b9525cb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larry Mackleberry  and  Jerry Mackleberry\n",
      "185  and  185\n"
     ]
    }
   ],
   "source": [
    "most_similar = None # Pair of two different documents\n",
    "\n",
    "# YOUR CODE HERE\n",
    "most_similar = np.unravel_index(np.argmax(lower_similarity_matrix, axis=None), lower_similarity_matrix.shape)\n",
    "\n",
    "print(titles[most_similar[0]], \" and \", titles[most_similar[1]])\n",
    "print(len(texts[most_similar[0]]), \" and \", len(texts[most_similar[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cd1338c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b0960c422fba3b99fe192a2043c19c2",
     "grade": true,
     "grade_id": "cell-95d5c5710a84f881",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Automatic unit tests, no need to modify/study this.\n",
    "assert most_similar[0] != most_similar[1]\n",
    "_a, _b = min(most_similar), max(most_similar)\n",
    "_tmp = similarity_matrix[_a].copy()\n",
    "_tmp[[_a,_b]] = -1\n",
    "assert similarity_matrix[_a, _b] >= _tmp.max()\n",
    "del _tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84483dab",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b85b6d2878eb60658cea76c45556d25c",
     "grade": false,
     "grade_id": "cell-6748d40dc76ea5bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Find the two most similar longer documents\n",
    "\n",
    "Now only consider documents that have at least 1000 characters in the body!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc4ed0f2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be922cc6f4e36d116842a2647a16a66b",
     "grade": false,
     "grade_id": "cell-1f98cf030b28c592",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "most_similar = None # Pair of two different documents\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# lengths = []\n",
    "from gensim.utils import tokenize\n",
    "# for i, text in enumerate(texts):\n",
    "#     # Tokenize first:\n",
    "#     tokens = tokenize(text)\n",
    "#     doc = [word for word in list(tokens) if word in model.key_to_index]\n",
    "#     if len(doc) >= 1000:\n",
    "#         lengths.append((i, len(doc)))\n",
    "\n",
    "# lengths\n",
    "        \n",
    "# print(titles[most_similar[0]], \" and \", titles[most_similar[1]])\n",
    "# print(len(texts[most_similar[0]]), \" and \", len(texts[most_similar[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06faff1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f985b4f5ea73ad8f575cad2ca7e3f47",
     "grade": true,
     "grade_id": "cell-752e14ca1c72439e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Automatic unit tests, no need to modify/study this.\n",
    "assert most_similar[0] != most_similar[1]\n",
    "_a, _b = min(most_similar), max(most_similar)\n",
    "assert len(texts[_a]) >= 1000 and len(texts[_b]) >= 1000, \"not long documents.\"\n",
    "_tmp = similarity_matrix[_a].copy()\n",
    "_tmp[[_a,_b]] = -1\n",
    "assert similarity_matrix[_a, _b] >= _tmp.max()\n",
    "del _tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97aeb66",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e669daaed900fd50491ab46d420587b",
     "grade": false,
     "grade_id": "cell-4b9453e9d424a987",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Run k-means and spherical k-means\n",
    "\n",
    "Cluster the document vectors (*not* the similarity matrix) with spherical k-means.\n",
    "\n",
    "Use k=10, and a fixed random seed of 42.\n",
    "\n",
    "Recall the assumptions of our spherical k-means implementation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c924d31",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1cbbc2cede2b8a253bc4a88734d898ca",
     "grade": false,
     "grade_id": "cell-9f095a62a0ad351f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "kcent = None # Compute the k-means cluster centers\n",
    "kassi = None # Compute the k-means cluster assignment\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# YOUR CODE HERE\n",
    "kmeans = KMeans(n_clusters=10, random_state=42).fit(document_vectors)\n",
    "kcent = kmeans.cluster_centers_\n",
    "kassi = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f1a784e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1ff12e3fef95ea9d4a229b1b07f9b4a",
     "grade": false,
     "grade_id": "cell-d0057aab79416deb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Minimalistic implementation for spherical k-means, so we use the same version in this assignment\n",
    "# This is NOT meant as an example of good code, but to be short.\n",
    "def initial_centers(X, k, seed):\n",
    "    return X[np.random.default_rng(seed=seed).choice(X.shape[0], k, replace=False)]\n",
    "\n",
    "def sphericalkmeans(X, centers, max_iter=100):\n",
    "    assert abs((X**2).sum()-len(X)) < 1e-7, \"Improper input for spherical k-means!\"\n",
    "    last_assignment = None\n",
    "    for iter in range(max_iter):\n",
    "        assignment = np.asarray((X @ centers.T).argmax(axis=1)).squeeze()\n",
    "        if last_assignment is not None and all(assignment == last_assignment): break\n",
    "        last_assignment, centers = assignment, np.zeros(centers.shape)\n",
    "        for i in range(centers.shape[0]):\n",
    "            c = X[assignment == i,:].sum(axis=0)\n",
    "            centers[i] = c / np.sqrt((c**2).sum())\n",
    "    return centers, assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76020f3c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ad3fb3b95f64eb90b0505614e5eceec",
     "grade": false,
     "grade_id": "cell-af9c058e1e8fb376",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "scent = None # Compute the spherical k-means cluster centers\n",
    "sassi = None # Compute the spherical k-means cluster assignment\n",
    "\n",
    "# First, let's normalize the input:\n",
    "from sklearn.preprocessing import normalize\n",
    "normalized_documents = normalize(document_vectors, 'l2')\n",
    "\n",
    "# Initialize the centers:\n",
    "init = initial_centers(document_vectors, 10, 42)\n",
    "\n",
    "# Compute Spherical K means:\n",
    "scent, sassi = sphericalkmeans(normalized_documents, init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b3180a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c82947798ec5e08604d2e5ad5677d5a3",
     "grade": false,
     "grade_id": "cell-d46789bc3daac2b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Explore your result\n",
    "\n",
    "Explore the result: write a function to determine the most important words for each factor, and the most relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1a1e3e5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b05e08bc5ed1147ab6e1540a8320cd7",
     "grade": false,
     "grade_id": "cell-277fe736a237351f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def most_central(tfidf, centers, assignment, i, k=5):\n",
    "    \"\"\"Find the most central documents of cluster i\"\"\"\n",
    "    central_docs = (tfidf@centers[i].T).flatten()*(assignment==i)\n",
    "    return central_docs.argsort() [-1::-1][:k]\n",
    "    \n",
    "def explain(tfidf, titles, classes, centers, assignment):\n",
    "    \"\"\"Explain the clusters: print\n",
    "    (1) relative size of each cluster\n",
    "    (2) three most frequent classes of each cluster\n",
    "    (3) five most central documents of each cluster\n",
    "    (4) ARI of the entire clustering\"\"\"\n",
    "    from sklearn.metrics import adjusted_rand_score\n",
    "    from collections import Counter\n",
    "        \n",
    "    # Relative size of each cluster:\n",
    "    print('----------------Size of Clusters-------------------\\n')\n",
    "    print('The Relative size of each cluster:')\n",
    "    [print('For Cluster: {}, There is {} documents'.format(el, sassi.tolist().count(el))) for el in list(set(assignment)) ]\n",
    "        \n",
    "    # Three most frequent classes of each cluster:\n",
    "    print('----------------Most frequent Classes-------------------\\n')\n",
    "    print('The most frequent classes of each cluster:')\n",
    "    print([classes[i[0]] for i in Counter(assignment).most_common(3)])\n",
    "    \n",
    "    # Five most central documents for each cluster:\n",
    "    print('----------------Central Documents-------------------\\n')\n",
    "    print('The Five most central documents for each cluster:')\n",
    "    print()\n",
    "    [print((titles[t[0]],titles[t[1]], titles[t[2]], titles[t[3]], titles[t[4]]), '\\n')  for t in [most_central(tfidf, centers, assignment, i, k=5) for i in np.unique(assignment)]]\n",
    "#     for i in np.unique(assignment):\n",
    "#         print('Cluster: {} has the following 5 central documents: \\n'.format(i))\n",
    "#         for t in most_central(tfidf, centers, assignment, i, k=5):\n",
    "#             print(titles[t])\n",
    "    print('---------------------####---------------------')\n",
    "    # ARI for the entire clustering:\n",
    "    print('----------------ARI-------------------\\n')\n",
    "    print('The ARI measure for the current assignment is: {}'.format(adjusted_rand_score(assignment, classes)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20a2b38b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f9e74a415ca091afd4c9fc3dd498e48",
     "grade": false,
     "grade_id": "cell-13dc9263d917f3fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular k-means clustering:\n",
      "----------------Size of Clusters-------------------\n",
      "\n",
      "The Relative size of each cluster:\n",
      "For Cluster: 0, There is 1218 documents\n",
      "For Cluster: 1, There is 2164 documents\n",
      "For Cluster: 2, There is 395 documents\n",
      "For Cluster: 3, There is 386 documents\n",
      "For Cluster: 4, There is 694 documents\n",
      "For Cluster: 5, There is 723 documents\n",
      "For Cluster: 6, There is 1672 documents\n",
      "For Cluster: 7, There is 1147 documents\n",
      "For Cluster: 8, There is 1045 documents\n",
      "For Cluster: 9, There is 682 documents\n",
      "----------------Most frequent Classes-------------------\n",
      "\n",
      "The most frequent classes of each cluster:\n",
      "['Episodes', 'Episodes', 'Episodes']\n",
      "----------------Central Documents-------------------\n",
      "\n",
      "The Five most central documents for each cluster:\n",
      "\n",
      "('Everytime We Say Good-Bye', 'Explode You', \"If You Think I'm Cuddly\", \"I Don't Know You\", '(You Make Me Feel Like) A Natural Woman') \n",
      "\n",
      "('Rotoscoped couch gag', 'Cake couch gag', 'Dice Couch Gag', 'The Couch Movie Trailer couch gag', 'Paintbrush couch gag') \n",
      "\n",
      "('Michael Cera', 'Steven Wright', 'Bobcat Goldthwait', 'Tom Waits', 'Jeff Ross (character)') \n",
      "\n",
      "('Little Bearded Woman', 'Gaston Simpson', 'Thad', 'Jeopardy Contestant 2', 'They Read, And Write, They Read and Read and Write') \n",
      "\n",
      "('That Girl', 'Highway to Hell', \"Marge's Lullaby 2\", 'Me and the Boys', 'Hallelujah Chorus') \n",
      "\n",
      "('Overpass Diner', 'Poverty Barn', 'Antiques', 'Aced Shoe', 'Gifts') \n",
      "\n",
      "('Birthplace of Jesus (Disputed)', 'Nuclear bomb', 'Struthiomimus', 'ATV (Quadbike)', 'Fort Sensible') \n",
      "\n",
      "('Babette Bouvier', 'Georgette Bouvier', 'Betsy Graycomb', 'Winifred Trout', 'Jacques Bouvier') \n",
      "\n",
      "('Stanlerina', 'Number 21', 'Rigellian Lisa', 'Pa (How Munched Is That Birdie in the Window?)', 'Rapunzel') \n",
      "\n",
      "('Radioactive Man 1 (The Simpsons)', 'Skull and Crossbones Baby', \"Homer's History\", 'Boy with Orange Beanie', 'Doofy') \n",
      "\n",
      "---------------------####---------------------\n",
      "----------------ARI-------------------\n",
      "\n",
      "The ARI measure for the current assignment is: 0.15108012592077263\n"
     ]
    }
   ],
   "source": [
    "print(\"Regular k-means clustering:\")\n",
    "explain(document_vectors, titles, classes, kcent, kassi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca7ba21e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc67ea4043ec95bb64eb2b386903ab11",
     "grade": false,
     "grade_id": "cell-0182fe0ca9eab638",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spherical k-means clustering:\n",
      "----------------Size of Clusters-------------------\n",
      "\n",
      "The Relative size of each cluster:\n",
      "For Cluster: 0, There is 1218 documents\n",
      "For Cluster: 1, There is 2164 documents\n",
      "For Cluster: 2, There is 395 documents\n",
      "For Cluster: 3, There is 386 documents\n",
      "For Cluster: 4, There is 694 documents\n",
      "For Cluster: 5, There is 723 documents\n",
      "For Cluster: 6, There is 1672 documents\n",
      "For Cluster: 7, There is 1147 documents\n",
      "For Cluster: 8, There is 1045 documents\n",
      "For Cluster: 9, There is 682 documents\n",
      "----------------Most frequent Classes-------------------\n",
      "\n",
      "The most frequent classes of each cluster:\n",
      "['Episodes', 'Episodes', 'Episodes']\n",
      "----------------Central Documents-------------------\n",
      "\n",
      "The Five most central documents for each cluster:\n",
      "\n",
      "('Gaston Simpson', 'Little Bearded Woman', 'Jeopardy Contestant 2', 'They Read, And Write, They Read and Read and Write', 'Joey (flashback)') \n",
      "\n",
      "('Stanlerina', 'Comedian', 'Rapunzel', 'Pa (How Munched Is That Birdie in the Window?)', 'Tommy') \n",
      "\n",
      "('Babette Bouvier', 'Betsy Graycomb', 'Georgette Bouvier', 'Winifred Trout', \"Linnea Penelope's Mother\") \n",
      "\n",
      "('Rotoscoped couch gag', 'Cake couch gag', 'Dice Couch Gag', 'The Couch Movie Trailer couch gag', 'Paintbrush couch gag') \n",
      "\n",
      "('Donut Truck', 'Overpass Diner', 'Poverty Barn', 'Goodbye Kitty', \"Skip's Diner\") \n",
      "\n",
      "('Everytime We Say Good-Bye', 'Explode You', \"If You Think I'm Cuddly\", '(You Make Me Feel Like) A Natural Woman', \"I Don't Know You\") \n",
      "\n",
      "('Number 21', 'Rigellian Lisa', 'Crackton', 'Knifey-Spoony guy', 'Thad') \n",
      "\n",
      "('Birthplace of Jesus (Disputed)', 'Nuclear bomb', 'Struthiomimus', 'ATV (Quadbike)', 'Emissaries to Byzantium') \n",
      "\n",
      "('Radioactive Man 1 (The Simpsons)', 'Michael Cera', 'Jeff Ross (character)', 'Tom Waits', 'Bobcat Goldthwait') \n",
      "\n",
      "('That Girl', 'Highway to Hell', \"Marge's Lullaby 2\", 'Me and the Boys', 'Oh, Danny Boy') \n",
      "\n",
      "---------------------####---------------------\n",
      "----------------ARI-------------------\n",
      "\n",
      "The ARI measure for the current assignment is: 0.14323470837516025\n"
     ]
    }
   ],
   "source": [
    "# Note: in case of poor performance, revisit your code above!\n",
    "print(\"Spherical k-means clustering:\")\n",
    "explain(document_vectors, titles, classes, scent, sassi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d08d6c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "728da5bf0a2aeed7cb38669cc448a60d",
     "grade": true,
     "grade_id": "cell-bff51f97df41d133",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14985cf8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19e587e1db977a132a84d4eaa0753566",
     "grade": true,
     "grade_id": "cell-0a5c008286289ff4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden unit tests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe6e91d",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All) to avoid typical problems with Jupyter notebooks. **Unfortunately, this does not work with Chrome right now, you will also need to reload the tab in Chrome afterwards**.\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\". Please put your name here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "283079d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Aymane Hachcham\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd18714",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513a025f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9b3a772f3391e481cdf37f3763446ba3",
     "grade": false,
     "grade_id": "cell-07702c6323035c14",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Setup our working context and load the data\n",
    "\n",
    "In this assignment, we will work with a database of inaugural speeches of US presidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41cdbef6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "629a869cb5c294f18b439df85ad29cf0",
     "grade": false,
     "grade_id": "cell-16c9afea02d4fc0f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, scipy.sparse\n",
    "import gzip, json\n",
    "inaugural = json.load(gzip.open(\"/data/datasets/inaugural.json.gz\",\"rt\"))\n",
    "labels = [t[0] for t in inaugural]\n",
    "speeches = [t[1] for t in inaugural]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c265ce4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fellow citizens, in the presence of this vast assemblage of my countrymen I am about to supplement and seal by the oath which I shall take the manifestation of the will of a great and free people. In the exercise of their power and right of self-government they have committed to one of their fellow-citizens a supreme and sacred trust, and he here consecrates himself to their service.\\n\\nThis impressive ceremony adds little to the solemn sense of responsibility with which I contemplate the duty I owe to all the people of the land. Nothing can relieve me from anxiety lest by any act of mine their interests may suffer, and nothing is needed to strengthen my resolution to engage every faculty and effort in the promotion of their welfare.\\n\\nAmid the din of party strife the people\\'s choice was made, but its attendant circumstances have demonstrated anew the strength and safety of a government by the people. In each succeeding year it more clearly appears that our democratic principle needs no apology, and that in its fearless and faithful application is to be found the surest guaranty of good government.\\n\\nBut the best results in the operation of a government wherein every citizen has a share largely depend upon a proper limitation of purely partisan zeal and effort and a correct appreciation of the time when the heat of the partisan should be merged in the patriotism of the citizen.\\n\\nToday the executive branch of the Government is transferred to new keeping. But this is still the Government of all the people, and it should be none the less an object of their affectionate solicitude. At this hour the animosities of political strife, the bitterness of partisan defeat, and the exultation of partisan triumph should be supplanted by an ungrudging acquiescence in the popular will and a sober, conscientious concern for the general weal. Moreover, if from this hour we cheerfully and honestly abandon all sectional prejudice and distrust, and determine, with manly confidence in one another, to work out harmoniously the achievements of our national destiny, we shall deserve to realize all the benefits which our happy form of government can bestow.\\n\\nOn this auspicious occasion we may well renew the pledge of our devotion to the Constitution, which, launched by the founders of the Republic and consecrated by their prayers and patriotic devotion, has for almost a century borne the hopes and the aspirations of a great people through prosperity and peace and through the shock of foreign conflicts and the perils of domestic strife and vicissitudes.\\n\\nBy the Father of his Country our Constitution was commended for adoption as \"the result of a spirit of amity and mutual concession.\" In that same spirit it should be administered, in order to promote the lasting welfare of the country and to secure the full measure of its priceless benefits to us and to those who will succeed to the blessings of our national life. The large variety of diverse and competing interests subject to Federal control, persistently seeking the recognition of their claims, need give us no fear that \"the greatest good to the greatest number\" will fail to be accomplished if in the halls of national legislation that spirit of amity and mutual concession shall prevail in which the Constitution had its birth. If this involves the surrender or postponement of private interests and the abandonment of local advantages, compensation will be found in the assurance that the common interest is subserved and the general welfare advanced.\\n\\nIn the discharge of my official duty I shall endeavor to be guided by a just and unstrained construction of the Constitution, a careful observance of the distinction between the powers granted to the Federal Government and those reserved to the States or to the people, and by a cautious appreciation of those functions which by the Constitution and laws have been especially assigned to the executive branch of the Government.\\n\\nBut he who takes the oath today to preserve, protect, and defend the Constitution of the United States only assumes the solemn obligation which every patriotic citizen -- on the farm, in the workshop, in the busy marts of trade, and everywhere -- should share with him. The Constitution which prescribes his oath, my countrymen, is yours; the Government you have chosen him to administer for a time is yours; the suffrage which executes the will of freemen is yours; the laws and the entire scheme of our civil rule, from the town meeting to the State capitals and the national capital, is yours. Your every voter, as surely as your Chief Magistrate, under the same high sanction, though in a different sphere, exercises a public trust. Nor is this all. Every citizen owes to the country a vigilant watch and close scrutiny of its public servants and a fair and reasonable estimate of their fidelity and usefulness. Thus is the people\\'s will impressed upon the whole framework of our civil polity--municipal, State, and Federal; and this is the price of our liberty and the inspiration of our faith in the Republic.\\n\\nIt is the duty of those serving the people in public place to closely limit public expenditures to the actual needs of the Government economically administered, because this bounds the right of the Government to exact tribute from the earnings of labor or the property of the citizen, and because public extravagance begets extravagance among the people. We should never be ashamed of the simplicity and prudential economies which are best suited to the operation of a republican form of government and most compatible with the mission of the American people. Those who are selected for a limited time to manage public affairs are still of the people, and may do much by their example to encourage, consistently with the dignity of their official functions, that plain way of life which among their fellow citizens aids integrity and promotes thrift and prosperity.\\n\\nThe genius of our institutions, the needs of our people in their home life, and the attention which is demanded for the settlement and development of the resources of our vast territory dictate the scrupulous avoidance of any departure from that foreign policy commended by the history, the traditions, and the prosperity of our Republic. It is the policy of independence, favored by our position and defended by our known love of justice and by our power. It is the policy of peace suitable to our interests. It is the policy of neutrality, rejecting any share in foreign broils and ambitions upon other continents and repelling their intrusion here. It is the policy of Monroe and of Washington and Jefferson -- \"Peace, commerce, and honest friendship with all nations; entangling alliance with none.\"\\n\\nA due regard for the interests and prosperity of all the people demands that our finances shall be established upon such a sound and sensible basis as shall secure the safety and confidence of business interests and make the wage of labor sure and steady, and that our system of revenue shall be so adjusted as to relieve the people of unnecessary taxation, having a due regard to the interests of capital invested and workingmen employed in American industries, and preventing the accumulation of a surplus in the Treasury to tempt extravagance and waste.\\n\\nCare for the property of the nation and for the needs of future settlers requires that the public domain should be protected from purloining schemes and unlawful occupation.\\n\\nThe conscience of the people demands that the Indians within our boundaries shall be fairly and honestly treated as wards of the Government and their education and civilization promoted with a view to their ultimate citizenship, and that polygamy in the Territories, destructive of the family relation and offensive to the moral sense of the civilized world, shall be repressed.\\n\\nThe laws should be rigidly enforced which prohibit the immigration of a servile class to compete with American labor, with no intention of acquiring citizenship, and bringing with them and retaining habits and customs repugnant to our civilization.\\n\\nThe people demand reform in the administration of the Government and the application of business principles to public affairs. As a means to this end, civil-service reform should be in good faith enforced. Our citizens have the right to protection from the incompetency of public employees who hold their places solely as the reward of partisan service, and from the corrupting influence of those who promise and the vicious methods of those who expect such rewards; and those who worthily seek public employment have the right to insist that merit and competency shall be recognized instead of party subserviency or the surrender of honest political belief.\\n\\nIn the administration of a government pledged to do equal and exact justice to all men there should be no pretext for anxiety touching the protection of the freedmen in their rights or their security in the enjoyment of their privileges under the Constitution and its amendments. All discussion as to their fitness for the place accorded to them as American citizens is idle and unprofitable except as it suggests the necessity for their improvement. The fact that they are citizens entitles them to all the rights due to that relation and charges them with all its duties, obligations, and responsibilities.\\n\\nThese topics and the constant and ever-varying wants of an active and enterprising population may well receive the attention and the patriotic endeavor of all who make and execute the Federal law. Our duties are practical and call for industrious application, an intelligent perception of the claims of public office, and, above all, a firm determination, by united action, to secure to all the people of the land the full benefits of the best form of government ever vouchsafed to man. And let us not trust to human effort alone, but humbly acknowledging the power and goodness of Almighty God, who presides over the destiny of nations, and who has at all times been revealed in our country\\'s history, let us invoke His aid and His blessings upon our labors.\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print Speeches:\n",
    "speeches[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db21fe5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b6d4b371cc85ac597319240c5c3bb7ab",
     "grade": false,
     "grade_id": "cell-af116721e56ca2d4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Build a Sparse Document-Term Matrix\n",
    "\n",
    "Build a document-term matrix for the inaugural speeches.\n",
    "\n",
    "Use sparse data structures, a minimum document frequency of 5, remove english stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798ce634",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a228b5191cd44fb130ca5fe332b7209",
     "grade": false,
     "grade_id": "cell-114c21537f268c42",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Vocabulary not fitted or provided",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotFittedError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m vectorizer \u001B[38;5;241m=\u001B[39m CountVectorizer(min_df\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, stop_words\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124menglish\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# dtm = vectorizer.fit_transform(input_text)\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m vocab \u001B[38;5;241m=\u001B[39m \u001B[43mvectorizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_feature_names_out\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(vocab)\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(dtm\u001B[38;5;241m.\u001B[39mtoarray())\n",
      "File \u001B[0;32m~/miniconda3/envs/tad/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1454\u001B[0m, in \u001B[0;36mCountVectorizer.get_feature_names_out\u001B[0;34m(self, input_features)\u001B[0m\n\u001B[1;32m   1441\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_feature_names_out\u001B[39m(\u001B[38;5;28mself\u001B[39m, input_features\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   1442\u001B[0m     \u001B[38;5;124;03m\"\"\"Get output feature names for transformation.\u001B[39;00m\n\u001B[1;32m   1443\u001B[0m \n\u001B[1;32m   1444\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1452\u001B[0m \u001B[38;5;124;03m        Transformed feature names.\u001B[39;00m\n\u001B[1;32m   1453\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1454\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_vocabulary\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1455\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39masarray(\n\u001B[1;32m   1456\u001B[0m         [t \u001B[38;5;28;01mfor\u001B[39;00m t, i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28msorted\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvocabulary_\u001B[38;5;241m.\u001B[39mitems(), key\u001B[38;5;241m=\u001B[39mitemgetter(\u001B[38;5;241m1\u001B[39m))],\n\u001B[1;32m   1457\u001B[0m         dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mobject\u001B[39m,\n\u001B[1;32m   1458\u001B[0m     )\n",
      "File \u001B[0;32m~/miniconda3/envs/tad/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:506\u001B[0m, in \u001B[0;36m_VectorizerMixin._check_vocabulary\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    504\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_vocabulary()\n\u001B[1;32m    505\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfixed_vocabulary_:\n\u001B[0;32m--> 506\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m NotFittedError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mVocabulary not fitted or provided\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    508\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvocabulary_) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    509\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mVocabulary is empty\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNotFittedError\u001B[0m: Vocabulary not fitted or provided"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer # Please use this\n",
    "vocab = None # Your vocabulary\n",
    "dtm = None # Your sparse document term matrix\n",
    "\n",
    "input_text = ['Fellow citizens, in the presence of this vast assemblage of my countrymen I am about to supplement and seal by the oath which I shall take the manifestation of the will of a great and free people.']\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=1, stop_words='english')\n",
    "# dtm = vectorizer.fit_transform(input_text)\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "    \n",
    "print(vocab)\n",
    "print(dtm.toarray())\n",
    "print(\"Document term matrix has shape\", dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b4270a4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "12a9b577516397351a3a62eeb85e9247",
     "grade": true,
     "grade_id": "cell-bd01a0831d1d883e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert dtm.shape[0] == len(speeches), \"Wrong number of speeches\"\n",
    "assert dtm.shape[1] > 2000, \"You have too few words\"\n",
    "assert dtm.shape[1] < 3000, \"You have too many words\"\n",
    "assert \"president\" in vocab, \"You lost the president\"\n",
    "assert not \"President\" in vocab, \"Please lowercase\"\n",
    "assert not \"the\" in vocab, \"You did not remove stopwords\"\n",
    "assert isinstance(dtm, scipy.sparse.csr_matrix), \"Generate a sparse matrix to conserve memory!\"\n",
    "assert dtm.sum(axis=0).min() == 5, \"Minimum document frequency not OK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf509367",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3043cde9006c7396a4eb4c122b36a591",
     "grade": true,
     "grade_id": "cell-4b94f699d027f9dd",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Additional tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5089997",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95b230861f6f5b8e321d5828de4ee7af",
     "grade": false,
     "grade_id": "cell-3f85d812bd765b82",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abiding</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>aboriginal</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absence</th>\n",
       "      <th>...</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yield</th>\n",
       "      <th>young</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zealously</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1885-Cleveland</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969-Nixon</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941-Roosevelt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937-Roosevelt</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965-Johnson</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                000  abandon  abandoned  abiding  abilities  ability  able  \\\n",
       "1885-Cleveland    0        1          0        0          0        0     0   \n",
       "1969-Nixon        0        0          0        0          0        0     0   \n",
       "1941-Roosevelt    0        0          0        0          0        0     0   \n",
       "1937-Roosevelt    0        1          0        1          0        1     0   \n",
       "1965-Johnson      0        1          0        1          0        0     0   \n",
       "\n",
       "                aboriginal  abroad  absence  ...  written  wrong  year  years  \\\n",
       "1885-Cleveland           0       0        0  ...        0      0     1      0   \n",
       "1969-Nixon               0       1        0  ...        0      0     1      5   \n",
       "1941-Roosevelt           0       0        0  ...        2      0     1      6   \n",
       "1937-Roosevelt           0       0        1  ...        0      0     1      4   \n",
       "1965-Johnson             0       0        0  ...        1      0     0      3   \n",
       "\n",
       "                yes  yield  young  zeal  zealous  zealously  \n",
       "1885-Cleveland    0      0      0     1        0          0  \n",
       "1969-Nixon        0      0      0     0        0          0  \n",
       "1941-Roosevelt    0      0      0     0        0          0  \n",
       "1937-Roosevelt    0      0      0     0        0          0  \n",
       "1965-Johnson      0      0      1     0        0          0  \n",
       "\n",
       "[5 rows x 2158 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pretty display the data with pandas:\n",
    "pd.DataFrame.sparse.from_spmatrix(dtm,index=labels,columns=vocab).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0538ed14",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "676f591867462c42d3a3a0f79829c09c",
     "grade": false,
     "grade_id": "cell-6ee37fd607632130",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Most Frequent Words for Each Speech\n",
    "\n",
    "Compute the most frequent word (except for the stopwords already removed) for each speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "231e4d95",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d694d6d8c9a2bb7668f42b8efbd9f3a",
     "grade": false,
     "grade_id": "cell-77c392efa46dae92",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1885-Cleveland': 'people', '1969-Nixon': 'people', '1941-Roosevelt': 'nation', '1937-Roosevelt': 'government', '1965-Johnson': 'change', '2001-Bush': 'america', '1881-Garfield': 'government', '1801-Jefferson': 'government', '1985-Reagan': 'government', '1789-Washington': 'government', '1829-Jackson': 'public', '1869-Grant': 'country', '1997-Clinton': 'new', '2013-Obama': 'people', '1893-Cleveland': 'people', '1913-Wilson': 'great', '1949-Truman': 'world', '1861-Lincoln': 'constitution', '2005-Bush': 'freedom', '1953-Eisenhower': 'free', '1805-Jefferson': 'public', '1945-Roosevelt': 'shall', '1817-Monroe': 'government', '1933-Roosevelt': 'national', '1901-McKinley': 'government', '1853-Pierce': 'power', '1977-Carter': 'nation', '1961-Kennedy': 'let', '1921-Harding': 'world', '1821-Monroe': 'great', '1809-Madison': 'nations', '1897-McKinley': 'people', '1833-Jackson': 'government', '1973-Nixon': 'let', '2017-Trump': 'america', '1929-Hoover': 'government', '1793-Washington': 'shall', '1993-Clinton': 'world', '1909-Taft': 'government', '1889-Harrison': 'people', '1841-Harrison': 'power', '1845-Polk': 'government', '1873-Grant': 'country', '1849-Taylor': 'shall', '2009-Obama': 'nation', '1989-Bush': 'new', '1857-Buchanan': 'states', '1837-VanBuren': 'people', '1917-Wilson': 'shall', '1813-Madison': 'war', '1865-Lincoln': 'war', '1925-Coolidge': 'country', '1957-Eisenhower': 'world', '1825-Adams': 'union', '1905-Roosevelt': 'life', '1981-Reagan': 'government', '1797-Adams': 'people', '1877-Hayes': 'country'}\n"
     ]
    }
   ],
   "source": [
    "# Build a dictionary speech label to most frequent word\n",
    "most_frequent = dict()\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "_sentences = re.compile(r'[.!\\n]\\s', re.U) \n",
    "_words = re.compile(r\"[\\w']+\", re.U)\n",
    "\n",
    "# Splitting the speech documents into sentences and words:\n",
    "dmt_frame = pd.DataFrame.sparse.from_spmatrix(dtm,index=labels,columns=vocab)\n",
    "count_per_doc = dmt_frame.T.sort_values(by='1885-Cleveland', ascending=True)\n",
    "\n",
    "for label_speech in inaugural:\n",
    "#     print(label_speech[0])\n",
    "#     print(count_per_doc[label_speech[0]])\n",
    "#     print(count_per_doc.index[ count_per_doc[label_speech[0]] == max(count_per_doc[label_speech[0]]) ].tolist())\n",
    "    vals = count_per_doc.index[ count_per_doc[label_speech[0]] == max(count_per_doc[label_speech[0]]) ]\n",
    "    most_frequent[label_speech[0]] = vals.tolist()[0]\n",
    "    \n",
    "\n",
    "print(most_frequent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa47fe6b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8eecf337958766ebc814f411a6f5534",
     "grade": true,
     "grade_id": "cell-1468d90cd2a01d90",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(most_frequent) == len(labels), \"You are missing some speeches\"\n",
    "assert set(most_frequent.keys()) == set(labels), \"You are missing some speeches\"\n",
    "assert not \"the\" in most_frequent.values(), \"Stopwords not removed\"\n",
    "assert \"america\" in most_frequent.values(), \"Someone talked about america\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116e0954",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d27a68be9c47b47a094507df12ddf42b",
     "grade": false,
     "grade_id": "cell-a4516e3e82efbcae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# TF-IDF\n",
    "\n",
    "From the document-term matrix, compute the TF-IDF matrix. Implement the standard version of TF-IDF (`ltc`).\n",
    "\n",
    "Be careful with 0 values, ensure that your matrix remains *sparse*. Do *not* rely on Wikipedia, it has errors.\n",
    "\n",
    "Perform the transformation in three steps, named `tf`, `idf`, `tfidf`. First implement term frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58b4f48a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b484b10e2769fa38e6990d1a39ee5c1",
     "grade": false,
     "grade_id": "cell-8a8c6fc0ed03272e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old sum: 44859 new sum: 33943.453 (must be less and float)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def tf(dtm):\n",
    "    \"\"\"Compute the \"l\" step of standard TF-IDF\"\"\"\n",
    "#     # HINT: use dtm.astype(np.float32) to get a *sparse floating point copy* of the dtm matrix.\n",
    "    \n",
    "    tf_matrix = dtm.astype(np.float32)\n",
    "    tf_matrix.data = 1 + np.log(tf_matrix.data)\n",
    "    \n",
    "    return tf_matrix\n",
    "    \n",
    "    \n",
    "print(\"Old sum:\", dtm.sum(), \"new sum:\", tf(dtm).sum(), \"(must be less and float)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eb6ac900",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76718de1efa4d0cf07332e4e279d707b",
     "grade": false,
     "grade_id": "cell-a27302a3ccc5288a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abiding</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>aboriginal</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absence</th>\n",
       "      <th>...</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yield</th>\n",
       "      <th>young</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zealously</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1885-Cleveland</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969-Nixon</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941-Roosevelt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.791759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937-Roosevelt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965-Johnson</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                000  abandon  abandoned  abiding  abilities  ability  able  \\\n",
       "1885-Cleveland  0.0      1.0        0.0      0.0        0.0      0.0   0.0   \n",
       "1969-Nixon      0.0      0.0        0.0      0.0        0.0      0.0   0.0   \n",
       "1941-Roosevelt  0.0      0.0        0.0      0.0        0.0      0.0   0.0   \n",
       "1937-Roosevelt  0.0      1.0        0.0      1.0        0.0      1.0   0.0   \n",
       "1965-Johnson    0.0      1.0        0.0      1.0        0.0      0.0   0.0   \n",
       "\n",
       "                aboriginal  abroad  absence  ...   written  wrong  year  \\\n",
       "1885-Cleveland         0.0     0.0      0.0  ...  0.000000    0.0   1.0   \n",
       "1969-Nixon             0.0     1.0      0.0  ...  0.000000    0.0   1.0   \n",
       "1941-Roosevelt         0.0     0.0      0.0  ...  1.693147    0.0   1.0   \n",
       "1937-Roosevelt         0.0     0.0      1.0  ...  0.000000    0.0   1.0   \n",
       "1965-Johnson           0.0     0.0      0.0  ...  1.000000    0.0   0.0   \n",
       "\n",
       "                   years  yes  yield  young  zeal  zealous  zealously  \n",
       "1885-Cleveland  0.000000  0.0    0.0    0.0   1.0      0.0        0.0  \n",
       "1969-Nixon      2.609438  0.0    0.0    0.0   0.0      0.0        0.0  \n",
       "1941-Roosevelt  2.791759  0.0    0.0    0.0   0.0      0.0        0.0  \n",
       "1937-Roosevelt  2.386294  0.0    0.0    0.0   0.0      0.0        0.0  \n",
       "1965-Johnson    2.098612  0.0    0.0    1.0   0.0      0.0        0.0  \n",
       "\n",
       "[5 rows x 2158 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect your matrix\n",
    "pd.DataFrame.sparse.from_spmatrix(tf(dtm),index=labels,columns=vocab).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d91d4213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.       , 1.       , 1.       , ..., 1.6931472, 1.       ,\n",
       "       1.       ], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = tf(dtm).toarray()\n",
    "matrix[matrix > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "97b606ee",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b962f7fd25cf7f6888f81da155e471d",
     "grade": true,
     "grade_id": "cell-b2c65f81a921e50b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Automatic tests\n",
    "_tf = tf(dtm)\n",
    "assert _tf.sum() < dtm.sum(), \"Weight sum has not decreased.\"\n",
    "assert (_tf > 0).sum() == (dtm > 0).sum(), \"Number of zeros must not change.\"\n",
    "assert (_tf[_tf > 0].min()) == 1, \"Scaling incorrect.\"\n",
    "assert _tf.dtype in [np.float32, np.float64, np.float16], \"Not using floating point.\"\n",
    "assert isinstance(_tf, scipy.sparse.csr_matrix), \"Not a sparse matrix anymore!\"\n",
    "# It is not allowed to only restore sparsity if it was lost.\n",
    "from unittest.mock import patch\n",
    "with patch('scipy.sparse.csr.csr_matrix') as mock_csr: tf(dtm)\n",
    "mock_csr.assert_not_called()\n",
    "del _tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a424e8cd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27def8267eae9e4d1b822f136c6feedc",
     "grade": false,
     "grade_id": "cell-bb839f352284f579",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Implement the `idf` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e8a25f7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "964c25f0133fa9eaf0df457bfe993303",
     "grade": false,
     "grade_id": "cell-6503b31d15a1af9b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def idf(dtm):\n",
    "    \"\"\" Compute the \"t\" step inverse document frequency \"\"\"\n",
    "    idf_matrix = np.log(dtm.shape[0] / (dtm.getnnz(0) + 1))\n",
    "    return idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7137860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.42138568 1.86321843 2.4510051  ... 1.57553636 2.4510051  2.26868354]\n",
      "(2158,)\n"
     ]
    }
   ],
   "source": [
    "b=(np.ones((dtm.shape[0],)) @ dtm)\n",
    "print(np.log(dtm.shape[0] / b))\n",
    "print(idf(dtm).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5893f762",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d66aa485275620ae976ae1ccc4f4a6f",
     "grade": true,
     "grade_id": "cell-5c95bc2a42c0a885",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Automatic tests\n",
    "_idf = idf(dtm)\n",
    "assert len(_idf.shape) == 1, \"Result must be one-dimensional.\"\n",
    "assert _idf.flatten().shape[0] == dtm.shape[1], \"The IDF dimension is not okay.\"\n",
    "assert _idf.dtype in [np.float32, np.float64, np.float16], \"Not using floating point.\"\n",
    "assert not isinstance(_idf, scipy.sparse.csr_matrix), \"IDF must not be sparse.\"\n",
    "assert _idf.min() > 0, \"IDF must not be zero here.\"\n",
    "assert _idf.max() < 3, \"Too large idf values.\"\n",
    "from unittest.mock import patch\n",
    "with patch('scipy.sparse.csr_matrix.todense') as mock_todense, patch('scipy.sparse.csr_matrix.toarray') as mock_toarray:\n",
    "    type(idf(dtm))\n",
    "mock_todense.assert_not_called()\n",
    "mock_toarray.assert_not_called()\n",
    "del _idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521d9792",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0c49aff76d97a67701f46e5e99e3fe14",
     "grade": false,
     "grade_id": "cell-3c65f666ba451e70",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now implement the full `tfidf` function, using above implementations of `df` and `idf`.\n",
    "\n",
    "Hint: you may find `scipy.sparse.spdiags` useful to keep the computations *sparse*.\n",
    "\n",
    "You are **not allowed** to use sklearns `TfidfVectorizer`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ddc376a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b60967a505a23c6fc1731604aa33317",
     "grade": false,
     "grade_id": "cell-8e543f615abb27f4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def tfidf(dtm):\n",
    "    \"\"\"Finish the computation of standard TF-IDF with the c step\"\"\"\n",
    "    _tf, _idf = tf(dtm), idf(dtm) # Must use above functions.\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    tf_idf = np.zeros(_tf.shape)\n",
    "    for row_index in range(0,_tf.shape[0]):\n",
    "        for col_index in range(0,_tf.shape[1]):\n",
    "            tf_idf[row_index, col_index] = _tf[row_index, col_index] * _idf[row_index]\n",
    "    \n",
    "    tf_idf = scipy.sparse.csr_matrix(tf_idf)\n",
    "    _norm = 1 / scipy.sparse.linalg.norm(tf_idf, ord=2, axis=1)\n",
    "    \n",
    "    for row_index in range(0,_tf.shape[0]):\n",
    "        tf_idf[row_index] = tf_idf[row_index] * _norm[row_index]\n",
    "    \n",
    "    \n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ec77694a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd3a678bc71fa04516812b2830070774",
     "grade": false,
     "grade_id": "cell-efc0715b6e7b9fbc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abiding</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>aboriginal</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absence</th>\n",
       "      <th>...</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yield</th>\n",
       "      <th>young</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zealously</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1885-Cleveland</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969-Nixon</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034816</td>\n",
       "      <td>0.090851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941-Roosevelt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044217</td>\n",
       "      <td>0.123442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937-Roosevelt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036023</td>\n",
       "      <td>0.085963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965-Johnson</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                000   abandon  abandoned   abiding  abilities   ability  able  \\\n",
       "1885-Cleveland  0.0  0.037491        0.0  0.000000        0.0  0.000000   0.0   \n",
       "1969-Nixon      0.0  0.000000        0.0  0.000000        0.0  0.000000   0.0   \n",
       "1941-Roosevelt  0.0  0.000000        0.0  0.000000        0.0  0.000000   0.0   \n",
       "1937-Roosevelt  0.0  0.036023        0.0  0.036023        0.0  0.036023   0.0   \n",
       "1965-Johnson    0.0  0.043708        0.0  0.043708        0.0  0.000000   0.0   \n",
       "\n",
       "                aboriginal    abroad   absence  ...   written  wrong  \\\n",
       "1885-Cleveland         0.0  0.000000  0.000000  ...  0.000000    0.0   \n",
       "1969-Nixon             0.0  0.034816  0.000000  ...  0.000000    0.0   \n",
       "1941-Roosevelt         0.0  0.000000  0.000000  ...  0.074865    0.0   \n",
       "1937-Roosevelt         0.0  0.000000  0.036023  ...  0.000000    0.0   \n",
       "1965-Johnson           0.0  0.000000  0.000000  ...  0.043708    0.0   \n",
       "\n",
       "                    year     years  yes  yield     young      zeal  zealous  \\\n",
       "1885-Cleveland  0.037491  0.000000  0.0    0.0  0.000000  0.037491      0.0   \n",
       "1969-Nixon      0.034816  0.090851  0.0    0.0  0.000000  0.000000      0.0   \n",
       "1941-Roosevelt  0.044217  0.123442  0.0    0.0  0.000000  0.000000      0.0   \n",
       "1937-Roosevelt  0.036023  0.085963  0.0    0.0  0.000000  0.000000      0.0   \n",
       "1965-Johnson    0.000000  0.091725  0.0    0.0  0.043708  0.000000      0.0   \n",
       "\n",
       "                zealously  \n",
       "1885-Cleveland        0.0  \n",
       "1969-Nixon            0.0  \n",
       "1941-Roosevelt        0.0  \n",
       "1937-Roosevelt        0.0  \n",
       "1965-Johnson          0.0  \n",
       "\n",
       "[5 rows x 2158 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect your matrix\n",
    "pd.DataFrame.sparse.from_spmatrix(tfidf(dtm),index=labels,columns=vocab).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "400d8b3f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44cda5eeed98b0e533db31996eae12c8",
     "grade": true,
     "grade_id": "cell-738b021a2edd333b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "_tfidf = tfidf(dtm)\n",
    "assert _tfidf.sum() < dtm.sum(), \"Weight sum has not decreased.\"\n",
    "assert (_tfidf > 0).sum() == (dtm > 0).sum(), \"Number of zeros must not change.\"\n",
    "assert abs(_tfidf.power(2).sum() - _tfidf.shape[0]) < 1e-5, \"Vectors are not 'c'.\"\n",
    "assert _tfidf.dtype in [np.float32, np.float64, np.float16], \"Not using floating point.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "56f3e817",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f9a68644a013dbb98aea3635b5fadd9",
     "grade": true,
     "grade_id": "cell-9f38132bf12a44aa",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from unittest.mock import patch\n",
    "with patch('scipy.sparse.csr_matrix.todense') as mock_todense, patch('scipy.sparse.csr_matrix.toarray') as mock_toarray:\n",
    "    assert isinstance(tfidf(dtm), scipy.sparse.csr_matrix), \"Not a sparse matrix anymore!\"\n",
    "mock_todense.assert_not_called()\n",
    "mock_toarray.assert_not_called()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5579dce7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a3cce83b3ac06c57e104183847b9e05a",
     "grade": false,
     "grade_id": "cell-c03f60fc44f715db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Compare to sklearn\n",
    "\n",
    "Now you are allowed to use `TfidfVectorizer`!\n",
    "\n",
    "Use sklearns `TfidfVectorizer` (make sure to choose parameters appropriately). Compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d17c073",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f85832a1736a887e5615508e6c702124",
     "grade": false,
     "grade_id": "cell-0b0f07f571d3b7ff",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tvect = TfidfVectorizer(stop_words='english',min_df=5) # set appropriate parameters!\n",
    "sktfidf = None # Store the TF-IDF result obtained via sklearn\n",
    "skvocab = None # The vocabulary\n",
    "# YOUR CODE HERE\n",
    "sktfidf = tvect.fit_transform(speeches)\n",
    "skvocab = tvect.get_feature_names_out()\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0efbbf5d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a2a40d1699746804bb8d3282af4243c",
     "grade": false,
     "grade_id": "cell-e029911a279ed4a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abiding</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>aboriginal</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absence</th>\n",
       "      <th>...</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yield</th>\n",
       "      <th>young</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zealously</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1885-Cleveland</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969-Nixon</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021913</td>\n",
       "      <td>0.070461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941-Roosevelt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030844</td>\n",
       "      <td>0.119010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937-Roosevelt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024533</td>\n",
       "      <td>0.063107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965-Johnson</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                000   abandon  abandoned   abiding  abilities   ability  able  \\\n",
       "1885-Cleveland  0.0  0.040356        0.0  0.000000        0.0  0.000000   0.0   \n",
       "1969-Nixon      0.0  0.000000        0.0  0.000000        0.0  0.000000   0.0   \n",
       "1941-Roosevelt  0.0  0.000000        0.0  0.000000        0.0  0.000000   0.0   \n",
       "1937-Roosevelt  0.0  0.037874        0.0  0.031740        0.0  0.026946   0.0   \n",
       "1965-Johnson    0.0  0.046402        0.0  0.038888        0.0  0.000000   0.0   \n",
       "\n",
       "                aboriginal    abroad   absence  ...   written  wrong  \\\n",
       "1885-Cleveland         0.0  0.000000  0.000000  ...  0.000000    0.0   \n",
       "1969-Nixon             0.0  0.024069  0.000000  ...  0.000000    0.0   \n",
       "1941-Roosevelt         0.0  0.000000  0.000000  ...  0.085117    0.0   \n",
       "1937-Roosevelt         0.0  0.000000  0.041508  ...  0.000000    0.0   \n",
       "1965-Johnson           0.0  0.000000  0.000000  ...  0.041473    0.0   \n",
       "\n",
       "                    year     years  yes  yield     young      zeal  zealous  \\\n",
       "1885-Cleveland  0.026141  0.000000  0.0    0.0  0.000000  0.038771      0.0   \n",
       "1969-Nixon      0.021913  0.070461  0.0    0.0  0.000000  0.000000      0.0   \n",
       "1941-Roosevelt  0.030844  0.119010  0.0    0.0  0.000000  0.000000      0.0   \n",
       "1937-Roosevelt  0.024533  0.063107  0.0    0.0  0.000000  0.000000      0.0   \n",
       "1965-Johnson    0.000000  0.057988  0.0    0.0  0.034736  0.000000      0.0   \n",
       "\n",
       "                zealously  \n",
       "1885-Cleveland        0.0  \n",
       "1969-Nixon            0.0  \n",
       "1941-Roosevelt        0.0  \n",
       "1937-Roosevelt        0.0  \n",
       "1965-Johnson          0.0  \n",
       "\n",
       "[5 rows x 2158 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pretty display the data with pandas:\n",
    "pd.DataFrame.sparse.from_spmatrix(sktfidf,index=labels,columns=skvocab).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1592d74",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71481abcbd33d985efcd9e197837ee8a",
     "grade": true,
     "grade_id": "cell-06545facc587412d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert all(skvocab == vocab), \"You did not use use same parameters as above.\"\n",
    "assert sktfidf.shape == dtm.shape, \"Matrix shapes do not agree.\"\n",
    "assert (sktfidf > 0).sum() == (dtm > 0).sum(), \"Sparsity must not change.\"\n",
    "assert abs(sktfidf.power(2).sum() - sktfidf.shape[0]) < 1e-7, \"Vectors are not 'c'.\"\n",
    "assert isinstance(sktfidf, scipy.sparse.csr_matrix), \"Not a sparse matrix anymore!\"\n",
    "assert sktfidf.dtype in [np.float32, np.float64, np.float16], \"Not using floating point.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c726c254",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "96615a622e9386a7758f054d77757f58",
     "grade": false,
     "grade_id": "cell-daae1edeb55afdeb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Understand the difference\n",
    "\n",
    "By visual inspection of the two matrixes, you will notice that they do *not* agree.\n",
    "\n",
    "Check the [bug reports of scikit-learn](https://github.com/scikit-learn/scikit-learn/issues?q=is%3Aissue+tf-idf+is%3Aopen) for related bug reports, and check the scikit-learn documentation *carefully* to figure out the difference.\n",
    "\n",
    "Is it better or worse? We don't know. But scikit-learn does not implement the standard approach!\n",
    "\n",
    "But: we can easily \"hack\" sklearn to produce the desired result.\n",
    "\n",
    "Hint: Use `fit`, adjust the vectorizer, and `tranform` separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32c5921c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "251444173b738d1f91e7c69d2e64a4a6",
     "grade": false,
     "grade_id": "cell-2ea02c1825ef9793",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Work around this issue in scikit-learn\n",
    "tvect2 = TfidfVectorizer(stop_words='english',min_df=5, smooth_idf=False, sublinear_tf=True, use_idf=False) # set appropriate parameters!\n",
    "sktfidf2 = None # Store the TF-IDF result obtained via sklearn\n",
    "skvocab2 = None # The vocabulary\n",
    "# Use fit(), adjust as necessary, transform() to get the desired result!\n",
    "# YOUR CODE HERE\n",
    "sktfidf2 = tvect2.fit(speeches)\n",
    "sktfidf2 = sktfidf2.transform(speeches)\n",
    "skvocab2 = tvect.get_feature_names_out()\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d81906ba",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b803c37e62bd6c9662d17127cc96760",
     "grade": false,
     "grade_id": "cell-00bb21a20d06a485",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abiding</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>aboriginal</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absence</th>\n",
       "      <th>...</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yield</th>\n",
       "      <th>young</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zealously</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1885-Cleveland</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969-Nixon</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034816</td>\n",
       "      <td>0.090851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941-Roosevelt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044217</td>\n",
       "      <td>0.123442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937-Roosevelt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036023</td>\n",
       "      <td>0.085963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965-Johnson</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                000   abandon  abandoned   abiding  abilities   ability  able  \\\n",
       "1885-Cleveland  0.0  0.037491        0.0  0.000000        0.0  0.000000   0.0   \n",
       "1969-Nixon      0.0  0.000000        0.0  0.000000        0.0  0.000000   0.0   \n",
       "1941-Roosevelt  0.0  0.000000        0.0  0.000000        0.0  0.000000   0.0   \n",
       "1937-Roosevelt  0.0  0.036023        0.0  0.036023        0.0  0.036023   0.0   \n",
       "1965-Johnson    0.0  0.043708        0.0  0.043708        0.0  0.000000   0.0   \n",
       "\n",
       "                aboriginal    abroad   absence  ...   written  wrong  \\\n",
       "1885-Cleveland         0.0  0.000000  0.000000  ...  0.000000    0.0   \n",
       "1969-Nixon             0.0  0.034816  0.000000  ...  0.000000    0.0   \n",
       "1941-Roosevelt         0.0  0.000000  0.000000  ...  0.074865    0.0   \n",
       "1937-Roosevelt         0.0  0.000000  0.036023  ...  0.000000    0.0   \n",
       "1965-Johnson           0.0  0.000000  0.000000  ...  0.043708    0.0   \n",
       "\n",
       "                    year     years  yes  yield     young      zeal  zealous  \\\n",
       "1885-Cleveland  0.037491  0.000000  0.0    0.0  0.000000  0.037491      0.0   \n",
       "1969-Nixon      0.034816  0.090851  0.0    0.0  0.000000  0.000000      0.0   \n",
       "1941-Roosevelt  0.044217  0.123442  0.0    0.0  0.000000  0.000000      0.0   \n",
       "1937-Roosevelt  0.036023  0.085963  0.0    0.0  0.000000  0.000000      0.0   \n",
       "1965-Johnson    0.000000  0.091725  0.0    0.0  0.043708  0.000000      0.0   \n",
       "\n",
       "                zealously  \n",
       "1885-Cleveland        0.0  \n",
       "1969-Nixon            0.0  \n",
       "1941-Roosevelt        0.0  \n",
       "1937-Roosevelt        0.0  \n",
       "1965-Johnson          0.0  \n",
       "\n",
       "[5 rows x 2158 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pretty display the data with pandas:\n",
    "pd.DataFrame.sparse.from_spmatrix(sktfidf2,index=labels,columns=skvocab2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef29c57a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0e0fee2ccb483f783bd871e26e6f9cf",
     "grade": true,
     "grade_id": "cell-ee90960893b6602f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert all(skvocab2 == vocab), \"You did not use use same parameters as above.\"\n",
    "assert sktfidf2.shape == dtm.shape, \"Matrix shapes do not agree.\"\n",
    "assert (sktfidf2 > 0).sum() == (dtm > 0).sum(), \"Sparsity must not change.\"\n",
    "assert abs(sktfidf2.power(2).sum() - sktfidf2.shape[0]) < 1e-7, \"Vectors are not 'c'.\"\n",
    "assert isinstance(sktfidf2, scipy.sparse.csr_matrix), \"Not a sparse matrix anymore!\"\n",
    "assert sktfidf2.dtype in [np.float32, np.float64, np.float16], \"Not using floating point.\"\n",
    "assert abs((sktfidf2 - sktfidf).sum()) > 1, \"Results are not different.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0dba6ad9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c3f5bd12b61ddb207a2a0a4ba9d012ce",
     "grade": true,
     "grade_id": "cell-7d9e8e611ddaa614",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.abs(sktfidf2 - tfidf(dtm)).sum() < 1e-3, \"Results are not similar.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d6eea8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "35f648ce1c5e7acecf0405c651fa9773",
     "grade": false,
     "grade_id": "cell-56763c0d14a02d66",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Compute the Cosine Similarity Matrix\n",
    "\n",
    "Compute the cosine similarity matrix of the speeches above.\n",
    "\n",
    "You are not allowed to use sklearn for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "323c9fff",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fdbfc6a982a04bfc19ce339f1448c7d",
     "grade": false,
     "grade_id": "cell-2999500654ff8d30",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix of shape 58 x 58\n"
     ]
    }
   ],
   "source": [
    "X = tfidf(dtm) # use your own tfidf results\n",
    "sim = None # Compute cosine similarities\n",
    "\n",
    "# YOUR CODE HERE\n",
    "sim = X.dot(X.transpose())\n",
    "del X # free memory again.\n",
    "print(\"Matrix of shape %d x %d\" % sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d758aa59",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c2195cdc44d0cab022a252f1c644f31",
     "grade": true,
     "grade_id": "cell-c3bc331c978c67ce",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert sim.shape[0] == dtm.shape[0] and sim.shape[1] == dtm.shape[0], \"Matrix size incorrect\"\n",
    "assert sim.max() < 1+1e07, \"Invalid values\"\n",
    "assert sim.min() > -1e07, \"Invalid values\"\n",
    "assert np.abs(sim.diagonal().mean() - 1) < 1e-8, \"Diagonal is not valid.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12aea19",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "385fef1c3e9ce6f29bf783ee889358f2",
     "grade": false,
     "grade_id": "cell-dce85dfc70e8ec47",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Find the two most similar speeches\n",
    "\n",
    "Given the similarity matrix, find the two most similar (different) speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b46bd79",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f482e21a6cd29aa79334b49a9d7f1751",
     "grade": false,
     "grade_id": "cell-2bd943f280c3ce4d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1817-Monroe\t1821-Monroe\t0.625993\n"
     ]
    }
   ],
   "source": [
    "most_similar = (None, None, None) # Store a pair of document *labels* and their similarity\n",
    "# YOUR CODE HERE\n",
    "most_similar = (0,0,0)\n",
    "for i in range(sim.shape[0]):\n",
    "    for j in range(sim.shape[0]):\n",
    "        if i != j and sim[i,j] >= most_similar[2]:\n",
    "            most_similar = (labels[j],labels[i],sim[i,j])\n",
    "\n",
    "\n",
    "print(\"%s\\t%s\\t%g\" % most_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "208c5ee0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a6a42a2e5b4904bb0a23de2aa3d74c71",
     "grade": true,
     "grade_id": "cell-1952f79fa08612ae",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(most_similar[0], str), \"Not a label\"\n",
    "assert isinstance(most_similar[1], str), \"Not a label\"\n",
    "assert isinstance(most_similar[2], float) or isinstance(most_similar[2], np.floating), \"Not a similarity\"\n",
    "assert most_similar[0] != most_similar[1]\n",
    "assert most_similar[2] > 0, \"There is definitely something similar.\"\n",
    "assert most_similar[2] < 1, \"There were no duplicate inaugural speeches yet.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca63318e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a198a8860cd12b9f5254093eb7f61d8",
     "grade": true,
     "grade_id": "cell-26b24a8ba7ab0196",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden tests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
